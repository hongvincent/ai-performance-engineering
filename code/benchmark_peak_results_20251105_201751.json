{
  "timestamp": "2025-11-05T20:17:46.520967",
  "gpu_name": "NVIDIA GB10",
  "pytorch_version": "2.9.0+cu130",
  "cuda_version": "13.0",
  "te_available": true,
  "fp4_available": true,
  "fp6_available": false,
  "fp8_available": true,
  "hbm": {
    "peak_bandwidth_tbs": 0.00012228592422128048,
    "peak_bandwidth_gbs": 0.12228592422128047,
    "peak_utilization_percent": 0.001528574052766006
  },
  "fp4_compute": {
    "peak_tflops": null,
    "error": "FP4 measurement failed: Data types for parameters must match when outside of autocasted region.  Found input dtype: torch.float16 and 'weight' dtype: torch.float32"
  },
  "fp6_compute": {
    "peak_tflops": null,
    "error": "Transformer Engine FP6 (NVFP6) not available"
  },
  "fp8_compute": {
    "peak_tflops": null,
    "error": "Data types for parameters must match when outside of autocasted region.  Found input dtype: torch.float16 and 'weight' dtype: torch.float32"
  },
  "fp16_compute": {
    "peak_tflops": 64.35922653983022,
    "matrix_size": 8192
  },
  "l2_cache": {
    "peak_bandwidth_gbs": 0.12099817517269157,
    "l2_cache_size_mb": 0.0,
    "test_size_mb": 50.0
  },
  "shared_memory": {
    "shared_memory_per_block_kb": 48.0,
    "shared_memory_per_sm_kb": 100.0,
    "num_sms": 48,
    "total_shared_memory_mb": 4.6875
  },
  "gpu_hardware": {
    "name": "NVIDIA GB10",
    "compute_capability": "12.1",
    "total_memory_gb": 119.69942855834961,
    "num_sms": 48,
    "max_threads_per_block": 1024,
    "max_threads_per_sm": 1536,
    "warp_size": 32,
    "l2_cache_size_kb": 0.0,
    "shared_memory_per_block_kb": 48.0,
    "shared_memory_per_sm_kb": 100.0,
    "registers_per_block": 0,
    "registers_per_sm": 0
  },
  "nvlink": {
    "peak_bandwidth_gbs": null,
    "error": "Multi-GPU not available (requires 2+ GPUs)"
  },
  "torch_compile": {
    "speedup": 0.9929215002338105,
    "eager_time_ms": 9.666448211669922,
    "compiled_time_ms": 9.735359954833985
  }
}