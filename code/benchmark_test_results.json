{
  "timestamp": "2025-11-05T20:14:38.054590",
  "results": [
    {
      "chapter": "ch1",
      "status": "completed",
      "benchmarks": [
        {
          "example": "nvlink",
          "baseline_file": "baseline_nvlink.py",
          "baseline_time_ms": 1.3182963180541991,
          "optimizations": [
            {
              "file": "optimized_nvlink.py",
              "technique": "optimized_nvlink",
              "status": "success",
              "time_ms": 0.8041420805454255,
              "speedup": 1.6393823304956734
            }
          ],
          "best_speedup": 1.6393823304956734,
          "status": "success",
          "error": null
        },
        {
          "example": "double",
          "baseline_file": "baseline_double_buffering.py",
          "baseline_time_ms": 4.129856014251709,
          "optimizations": [
            {
              "file": "optimized_double_buffering.py",
              "technique": "buffering",
              "status": "success",
              "time_ms": 6.40063886642456,
              "speedup": 0.6452255939505418
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "continuous",
          "baseline_file": "baseline_continuous_batching.py",
          "baseline_time_ms": 0.3000064007937908,
          "optimizations": [
            {
              "file": "optimized_continuous_batching.py",
              "technique": "batching",
              "status": "success",
              "time_ms": 0.8624944046139718,
              "speedup": 0.3478357647178769
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "cutlass",
          "baseline_file": "baseline_cutlass.py",
          "baseline_time_ms": 0.10388831986114383,
          "optimizations": [
            {
              "file": "optimized_cutlass.py",
              "technique": "optimized_cutlass",
              "status": "success",
              "time_ms": 0.14400895945727826,
              "speedup": 0.7214017811993383
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "kv",
          "baseline_file": "baseline_kv_cache.py",
          "baseline_time_ms": 6.170739221572876,
          "optimizations": [
            {
              "file": "optimized_kv_cache.py",
              "technique": "cache",
              "status": "success",
              "time_ms": 7.230524730682373,
              "speedup": 0.8534289628230783
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "speculative",
          "baseline_file": "baseline_speculative_decoding.py",
          "baseline_time_ms": 0.7656223967671394,
          "optimizations": [
            {
              "file": "optimized_speculative_decoding.py",
              "technique": "decoding",
              "status": "success",
              "time_ms": 0.7915615990757943,
              "speedup": 0.9672303427314555
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "moe",
          "baseline_file": "baseline_moe.py",
          "baseline_time_ms": 0.2057555192708969,
          "optimizations": [
            {
              "file": "optimized_moe.py",
              "technique": "optimized_moe",
              "status": "success",
              "time_ms": 0.6200908800959587,
              "speedup": 0.3318151030362781
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "shared",
          "baseline_file": "baseline_shared_memory.py",
          "baseline_time_ms": 0.051635520067065954,
          "optimizations": [
            {
              "file": "optimized_shared_memory.py",
              "technique": "memory",
              "status": "success",
              "time_ms": 0.06812255980446935,
              "speedup": 0.7579797385076871
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "coalescing",
          "baseline_file": "baseline_coalescing.py",
          "baseline_time_ms": 0.14564416021108628,
          "optimizations": [
            {
              "file": "optimized_coalescing.py",
              "technique": "optimized_coalescing",
              "status": "success",
              "time_ms": 0.41858304023742676,
              "speedup": 0.34794567913806224
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "warp",
          "baseline_file": "baseline_warp_specialization.py",
          "baseline_time_ms": 0.05156256012618542,
          "optimizations": [
            {
              "file": "optimized_warp_divergence.py",
              "technique": "divergence",
              "status": "success",
              "time_ms": 0.15105407942086457,
              "speedup": 0.34135165580349935
            },
            {
              "file": "optimized_warp_specialization.py",
              "technique": "specialization",
              "status": "success",
              "time_ms": 0.04915648002177477,
              "speedup": 1.0489473636709712
            }
          ],
          "best_speedup": 1.0489473636709712,
          "status": "success",
          "error": null
        },
        {
          "example": "ilp",
          "baseline_file": "baseline_ilp_basic.py",
          "baseline_time_ms": 0.14345247991383075,
          "optimizations": [
            {
              "file": "optimized_ilp_basic.py",
              "technique": "basic",
              "status": "success",
              "time_ms": 0.2332179206609726,
              "speedup": 0.6151005870700935
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "warp",
          "baseline_file": "baseline_warp_divergence.py",
          "baseline_time_ms": 0.07681952003389597,
          "optimizations": [
            {
              "file": "optimized_warp_divergence.py",
              "technique": "divergence",
              "status": "success",
              "time_ms": 0.1108473601192236,
              "speedup": 0.69302074448387
            },
            {
              "file": "optimized_warp_specialization.py",
              "technique": "specialization",
              "status": "success",
              "time_ms": 0.06879712000489235,
              "speedup": 1.1166095329053471
            }
          ],
          "best_speedup": 1.1166095329053471,
          "status": "success",
          "error": null
        },
        {
          "example": "performance",
          "baseline_file": "baseline_performance.py",
          "baseline_time_ms": 0.809638398885727,
          "optimizations": [
            {
              "file": "optimized_performance_pinned.py",
              "technique": "pinned",
              "status": "success",
              "time_ms": 1.3717471927404403,
              "speedup": 0.5902242068877522
            },
            {
              "file": "optimized_performance_batch.py",
              "technique": "batch",
              "status": "success",
              "time_ms": 0.47269600108265875,
              "speedup": 1.7128099180685648
            },
            {
              "file": "optimized_performance_graphs.py",
              "technique": "graphs",
              "status": "success",
              "time_ms": 0.5219439981505275,
              "speedup": 1.551197833013934
            }
          ],
          "best_speedup": 1.7128099180685648,
          "status": "success",
          "error": null
        },
        {
          "example": "disaggregated",
          "baseline_file": "baseline_disaggregated.py",
          "baseline_time_ms": 0.05661920011043549,
          "optimizations": [
            {
              "file": "optimized_disaggregated.py",
              "technique": "optimized_disaggregated",
              "status": "success",
              "time_ms": 0.0636863999068737,
              "speedup": 0.8890312561744371
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "nccl",
          "baseline_file": "baseline_nccl.py",
          "baseline_time_ms": 0.014094080021604895,
          "optimizations": [
            {
              "file": "optimized_nccl.py",
              "technique": "optimized_nccl",
              "status": "success",
              "time_ms": 0.05854591963812709,
              "speedup": 0.24073547923955324
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "guided",
          "baseline_file": "baseline_guided_decoding.py",
          "baseline_time_ms": 0.200331199914217,
          "optimizations": [
            {
              "file": "optimized_guided_decoding.py",
              "technique": "decoding",
              "status": "success",
              "time_ms": 0.7688655972480773,
              "speedup": 0.2605542511347135
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "attention",
          "baseline_file": "baseline_attention.py",
          "baseline_time_ms": 0.7025855988264084,
          "optimizations": [
            {
              "file": "optimized_attention.py",
              "technique": "optimized_attention",
              "status": "success",
              "time_ms": 0.3870464026927948,
              "speedup": 1.815249008744986
            }
          ],
          "best_speedup": 1.815249008744986,
          "status": "success",
          "error": null
        },
        {
          "example": "gemm",
          "baseline_file": "baseline_gemm.cu",
          "type": "cuda",
          "baseline_time_ms": 487.57407235001426,
          "optimizations": [
            {
              "file": "optimized_gemm_batched.cu",
              "technique": "batched",
              "status": "success",
              "time_ms": 496.11519540001154,
              "speedup": 0.982783992247787
            },
            {
              "file": "optimized_gemm_strided.cu",
              "technique": "strided",
              "status": "success",
              "time_ms": 392.3801381999965,
              "speedup": 1.2426064035420095
            }
          ],
          "best_speedup": 1.2426064035420095,
          "status": "success",
          "error": null
        },
        {
          "example": "arithmetic",
          "baseline_file": "baseline_arithmetic_intensity.cu",
          "type": "cuda",
          "baseline_time_ms": 569.7492769000062,
          "optimizations": [
            {
              "file": "optimized_arithmetic_intensity_combined.cu",
              "technique": "intensity_combined",
              "status": "success",
              "time_ms": 700.8537839999975,
              "speedup": 0.8129360073484432
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 19,
        "successful": 19,
        "failed": 0,
        "skipped_hardware": 0,
        "total_speedups": 6,
        "average_speedup": 1.4292674262379252,
        "max_speedup": 1.815249008744986,
        "min_speedup": 1.0489473636709712
      }
    },
    {
      "chapter": "ch10",
      "status": "completed",
      "benchmarks": [
        {
          "example": "flash",
          "baseline_file": "baseline_flash_attention.py",
          "baseline_time_ms": 1.054620804786682,
          "optimizations": [
            {
              "file": "optimized_flash_attention.py",
              "technique": "attention",
              "status": "success",
              "time_ms": 0.9395955264568329,
              "speedup": 1.122419993594056
            }
          ],
          "best_speedup": 1.122419993594056,
          "status": "success",
          "error": null
        },
        {
          "example": "streams",
          "baseline_file": "baseline_streams.py",
          "baseline_time_ms": 4.735520623922348,
          "optimizations": [
            {
              "file": "optimized_streams.py",
              "technique": "optimized_streams",
              "status": "success",
              "time_ms": 2.695139833688736,
              "speedup": 1.7570593424241812
            }
          ],
          "best_speedup": 1.7570593424241812,
          "status": "success",
          "error": null
        },
        {
          "example": "continuous",
          "baseline_file": "baseline_continuous_batching.py",
          "baseline_time_ms": 24.885772705078125,
          "optimizations": [
            {
              "file": "optimized_continuous_batching.py",
              "technique": "batching",
              "status": "success",
              "time_ms": 0.02969919978058897,
              "speedup": 837.927381509557
            }
          ],
          "best_speedup": 837.927381509557,
          "status": "success",
          "error": null
        },
        {
          "example": "cluster",
          "baseline_file": "baseline_cluster_group.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: Benchmark execution failed: Failed to build baseline_cluster_group_sm121 (arch=sm_121).\nstdout:\n\nstderr:\nmake: *** No rule to make target 'baseline_cluster_group_sm121'.  Stop.\n"
        },
        {
          "example": "roofline",
          "baseline_file": "baseline_roofline.py",
          "baseline_time_ms": 0.1221407999098301,
          "optimizations": [
            {
              "file": "optimized_roofline.py",
              "technique": "optimized_roofline",
              "status": "success",
              "time_ms": 1.1383904087543488,
              "speedup": 0.10729254126752454
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "warp",
          "baseline_file": "baseline_warp_divergence.py",
          "baseline_time_ms": 0.08950272008776665,
          "optimizations": [
            {
              "file": "optimized_warp_divergence.py",
              "technique": "divergence",
              "status": "success",
              "time_ms": 0.030296960063278675,
              "speedup": 2.9541815383731556
            }
          ],
          "best_speedup": 2.9541815383731556,
          "status": "success",
          "error": null
        },
        {
          "example": "triton",
          "baseline_file": "baseline_triton.py",
          "baseline_time_ms": 0.08349887989461421,
          "optimizations": [
            {
              "file": "optimized_triton.py",
              "technique": "optimized_triton",
              "status": "success",
              "time_ms": 0.09050815962255002,
              "speedup": 0.9225563777103977
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "matmul",
          "baseline_file": "baseline_matmul.py",
          "baseline_time_ms": 49.604492568969725,
          "optimizations": [
            {
              "file": "optimized_matmul_tensor_cores.py",
              "technique": "tensor_cores",
              "status": "success",
              "time_ms": 22.579737396240233,
              "speedup": 2.196858701165825
            }
          ],
          "best_speedup": 2.196858701165825,
          "status": "success",
          "error": null
        },
        {
          "example": "batch",
          "baseline_file": "baseline_batch.py",
          "baseline_time_ms": 0.11352447964251042,
          "optimizations": [
            {
              "file": "optimized_batch.py",
              "technique": "optimized_batch",
              "status": "success",
              "time_ms": 0.19158783823251724,
              "speedup": 0.5925453342436768
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "nccl",
          "baseline_file": "baseline_nccl.py",
          "baseline_time_ms": 1.098651521205902,
          "optimizations": [
            {
              "file": "optimized_nccl.py",
              "technique": "optimized_nccl",
              "status": "success",
              "time_ms": 0.10591296024620533,
              "speedup": 10.373154698461605
            }
          ],
          "best_speedup": 10.373154698461605,
          "status": "success",
          "error": null
        },
        {
          "example": "cooperative",
          "baseline_file": "baseline_cooperative_persistent.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: Benchmark execution failed: Failed to build baseline_cooperative_persistent_sm121 (arch=sm_121).\nstdout:\n\nstderr:\nmake: *** No rule to make target 'baseline_cooperative_persistent_sm121'.  Stop.\n"
        },
        {
          "example": "double",
          "baseline_file": "baseline_double_buffered_pipeline.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: Benchmark execution failed: Failed to build baseline_double_buffered_pipeline_sm121 (arch=sm_121).\nstdout:\n\nstderr:\nmake: *** No rule to make target 'baseline_double_buffered_pipeline_sm121'.  Stop.\n"
        },
        {
          "example": "attention",
          "baseline_file": "baseline_attention.py",
          "baseline_time_ms": 0.3223206388950348,
          "optimizations": [
            {
              "file": "optimized_attention.py",
              "technique": "optimized_attention",
              "status": "success",
              "time_ms": 0.11241023942828178,
              "speedup": 2.867360131375548
            }
          ],
          "best_speedup": 2.867360131375548,
          "status": "success",
          "error": null
        },
        {
          "example": "cluster",
          "baseline_file": "baseline_cluster_group.cu",
          "type": "cuda",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline executable not found for baseline_cluster_group.cu"
        },
        {
          "example": "double",
          "baseline_file": "baseline_double_buffered_pipeline.cu",
          "type": "cuda",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline executable not found for baseline_double_buffered_pipeline.cu"
        },
        {
          "example": "cooperative",
          "baseline_file": "baseline_cooperative_persistent.cu",
          "type": "cuda",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline executable not found for baseline_cooperative_persistent.cu"
        }
      ],
      "summary": {
        "total_benchmarks": 16,
        "successful": 10,
        "failed": 6,
        "skipped_hardware": 0,
        "total_speedups": 7,
        "average_speedup": 122.74263084499306,
        "max_speedup": 837.927381509557,
        "min_speedup": 1.122419993594056
      }
    },
    {
      "chapter": "ch11",
      "status": "completed",
      "benchmarks": [
        {
          "example": "coalescing",
          "baseline_file": "baseline_coalescing_streams.py",
          "baseline_time_ms": 0.025743680107407272,
          "optimizations": [
            {
              "file": "optimized_coalescing_streams.py",
              "technique": "streams",
              "status": "success",
              "time_ms": 0.11474368217168376,
              "speedup": 0.22435814870302506
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "streams",
          "baseline_file": "baseline_streams.py",
          "baseline_time_ms": 3.3576224366823832,
          "optimizations": [
            {
              "file": "optimized_streams.py",
              "technique": "optimized_streams",
              "status": "success",
              "time_ms": 0.8613866666952769,
              "speedup": 3.8979271057955347
            }
          ],
          "best_speedup": 3.8979271057955347,
          "status": "success",
          "error": null
        },
        {
          "example": "distributed",
          "baseline_file": "baseline_distributed_streams.py",
          "baseline_time_ms": 0.02909056001342833,
          "optimizations": [
            {
              "file": "optimized_distributed_streams.py",
              "technique": "streams",
              "status": "success",
              "time_ms": 0.07128159989602864,
              "speedup": 0.4081075629034678
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "tiling",
          "baseline_file": "baseline_tiling_streams.py",
          "baseline_time_ms": 0.025079039949923755,
          "optimizations": [
            {
              "file": "optimized_tiling_streams.py",
              "technique": "streams",
              "status": "success",
              "time_ms": 0.8730694389343262,
              "speedup": 0.028725137808666607
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "adaptive",
          "baseline_file": "baseline_adaptive_streams.py",
          "baseline_time_ms": 0.08742111973464489,
          "optimizations": [
            {
              "file": "optimized_adaptive_streams.py",
              "technique": "streams",
              "status": "success",
              "time_ms": 0.039455359857529404,
              "speedup": 2.2156969306658603
            }
          ],
          "best_speedup": 2.2156969306658603,
          "status": "success",
          "error": null
        },
        {
          "example": "gemm",
          "baseline_file": "baseline_gemm_streams.py",
          "baseline_time_ms": 0.003460799992317334,
          "optimizations": [
            {
              "file": "optimized_gemm_streams.py",
              "technique": "streams",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: "
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "disaggregated",
          "baseline_file": "baseline_disaggregated_streams.py",
          "baseline_time_ms": 0.047475199680775404,
          "optimizations": [
            {
              "file": "optimized_disaggregated_streams.py",
              "technique": "streams",
              "status": "success",
              "time_ms": 0.03664800012484193,
              "speedup": 1.2954376642395347
            }
          ],
          "best_speedup": 1.2954376642395347,
          "status": "success",
          "error": null
        },
        {
          "example": "tensor",
          "baseline_file": "baseline_tensor_cores_streams.py",
          "baseline_time_ms": 0.004944319915957749,
          "optimizations": [
            {
              "file": "optimized_tensor_cores_streams.py",
              "technique": "cores_streams",
              "status": "success",
              "time_ms": 0.001887999983737245,
              "speedup": 2.6188135373659276
            }
          ],
          "best_speedup": 2.6188135373659276,
          "status": "success",
          "error": null
        },
        {
          "example": "stream",
          "baseline_file": "baseline_stream_ordered_kv_cache.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: Benchmark execution failed: name 'batch_size' is not defined"
        },
        {
          "example": "streams",
          "baseline_file": "baseline_streams.cu",
          "type": "cuda",
          "baseline_time_ms": 319.27142110001796,
          "optimizations": [
            {
              "file": "optimized_streams_ordered.cu",
              "technique": "ordered",
              "status": "success",
              "time_ms": 242.46893264996743,
              "speedup": 1.3167518725416423
            },
            {
              "file": "optimized_streams_warp_specialized.cu",
              "technique": "warp_specialized",
              "status": "success",
              "time_ms": 415.9034308999935,
              "speedup": 0.7676575795711306
            }
          ],
          "best_speedup": 1.3167518725416423,
          "status": "success",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 10,
        "successful": 8,
        "failed": 2,
        "skipped_hardware": 0,
        "total_speedups": 5,
        "average_speedup": 2.2689254221216997,
        "max_speedup": 3.8979271057955347,
        "min_speedup": 1.2954376642395347
      }
    },
    {
      "chapter": "ch12",
      "status": "completed",
      "benchmarks": [
        {
          "example": "kernel",
          "baseline_file": "baseline_kernel_launches.py",
          "baseline_time_ms": 28.64659620920817,
          "optimizations": [
            {
              "file": "optimized_kernel_fusion.py",
              "technique": "fusion",
              "status": "success",
              "time_ms": 0.07564160078763962,
              "speedup": 378.71483298763326
            },
            {
              "file": "optimized_kernel_launches_graphs.py",
              "technique": "launches_graphs",
              "status": "success",
              "time_ms": 19.742943305969238,
              "speedup": 1.4509790037510228
            }
          ],
          "best_speedup": 378.71483298763326,
          "status": "success",
          "error": null
        },
        {
          "example": "nvlink",
          "baseline_file": "baseline_nvlink.py",
          "baseline_time_ms": 89.76022953033447,
          "optimizations": [
            {
              "file": "optimized_nvlink.py",
              "technique": "optimized_nvlink",
              "status": "success",
              "time_ms": 3.056743035316467,
              "speedup": 29.364663137620113
            }
          ],
          "best_speedup": 29.364663137620113,
          "status": "success",
          "error": null
        },
        {
          "example": "continuous",
          "baseline_file": "baseline_continuous_batching.py",
          "baseline_time_ms": 5.212156796455384,
          "optimizations": [
            {
              "file": "optimized_continuous_batching.py",
              "technique": "batching",
              "status": "success",
              "time_ms": 0.01568000018596649,
              "speedup": 332.40795501521956
            }
          ],
          "best_speedup": 332.40795501521956,
          "status": "success",
          "error": null
        },
        {
          "example": "cuda",
          "baseline_file": "baseline_cuda_graphs.py",
          "baseline_time_ms": 0.12439679950475693,
          "optimizations": [
            {
              "file": "optimized_cuda_graphs.py",
              "technique": "graphs",
              "status": "success",
              "time_ms": 0.5644672036170959,
              "speedup": 0.22037914462988184
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "distributed",
          "baseline_file": "baseline_distributed.py",
          "baseline_time_ms": 0.1779526400566101,
          "optimizations": [
            {
              "file": "optimized_distributed.py",
              "technique": "optimized_distributed",
              "status": "success",
              "time_ms": 0.03791935995221138,
              "speedup": 4.692923094716747
            }
          ],
          "best_speedup": 4.692923094716747,
          "status": "success",
          "error": null
        },
        {
          "example": "quantization",
          "baseline_file": "baseline_quantization.py",
          "baseline_time_ms": 0.1461702413856983,
          "optimizations": [
            {
              "file": "optimized_quantization.py",
              "technique": "optimized_quantization",
              "status": "success",
              "time_ms": 0.04526015996932983,
              "speedup": 3.229556446215598
            }
          ],
          "best_speedup": 3.229556446215598,
          "status": "success",
          "error": null
        },
        {
          "example": "roofline",
          "baseline_file": "baseline_roofline.py",
          "baseline_time_ms": 0.07663935966789723,
          "optimizations": [
            {
              "file": "optimized_roofline.py",
              "technique": "optimized_roofline",
              "status": "success",
              "time_ms": 0.09623936049640179,
              "speedup": 0.7963411152421637
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "graph",
          "baseline_file": "baseline_graph_bandwidth.py",
          "baseline_time_ms": 36.032799530029294,
          "optimizations": [
            {
              "file": "optimized_graph_bandwidth.py",
              "technique": "bandwidth",
              "status": "success",
              "time_ms": 35.98000640869141,
              "speedup": 1.001467290492898
            }
          ],
          "best_speedup": 1.001467290492898,
          "status": "success",
          "error": null
        },
        {
          "example": "work",
          "baseline_file": "baseline_work_queue.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: Benchmark execution failed: Failed to load work_queue CUDA extension: /home/cfregly/ai-performance-engineering/code/ch12/cuda_extensions/build/work_queue_kernels.so: undefined symbol: _ZNK2at10TensorBase8data_ptrIKfEEPT_v"
        },
        {
          "example": "kernel",
          "baseline_file": "baseline_kernel_fusion.py",
          "baseline_time_ms": 0.12322560101747512,
          "optimizations": [
            {
              "file": "optimized_kernel_fusion.py",
              "technique": "fusion",
              "status": "success",
              "time_ms": 0.04200320020318031,
              "speedup": 2.933719345702259
            },
            {
              "file": "optimized_kernel_launches_graphs.py",
              "technique": "launches_graphs",
              "status": "success",
              "time_ms": 19.102973442077637,
              "speedup": 0.006450597933934683
            }
          ],
          "best_speedup": 2.933719345702259,
          "status": "success",
          "error": null
        },
        {
          "example": "nccl",
          "baseline_file": "baseline_nccl.py",
          "baseline_time_ms": 1.0256057649850845,
          "optimizations": [
            {
              "file": "optimized_nccl.py",
              "technique": "optimized_nccl",
              "status": "success",
              "time_ms": 0.11007103942334652,
              "speedup": 9.317671299900065
            }
          ],
          "best_speedup": 9.317671299900065,
          "status": "success",
          "error": null
        },
        {
          "example": "hbm",
          "baseline_file": "baseline_hbm.py",
          "baseline_time_ms": 0.11456319987773896,
          "optimizations": [
            {
              "file": "optimized_hbm.py",
              "technique": "optimized_hbm",
              "status": "success",
              "time_ms": 0.18375423923134804,
              "speedup": 0.6234588130154809
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "attention",
          "baseline_file": "baseline_attention.py",
          "baseline_time_ms": 0.1876038409024477,
          "optimizations": [
            {
              "file": "optimized_attention.py",
              "technique": "optimized_attention",
              "status": "success",
              "time_ms": 0.21936063677072526,
              "speedup": 0.8552301983811725
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "bank",
          "baseline_file": "baseline_bank_conflicts.py",
          "baseline_time_ms": 0.10854528091847897,
          "optimizations": [
            {
              "file": "optimized_bank_conflicts.py",
              "technique": "conflicts",
              "status": "success",
              "time_ms": 0.1393875204026699,
              "speedup": 0.7787302665612225
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "cuda",
          "baseline_file": "baseline_cuda_graphs_conditional_enhanced.cu",
          "type": "cuda",
          "baseline_time_ms": 1315.316530099949,
          "optimizations": [
            {
              "file": "optimized_cuda_graphs_conditional.cu",
              "technique": "graphs_conditional",
              "status": "success",
              "time_ms": 290.847509550008,
              "speedup": 4.5223578917178076
            },
            {
              "file": "optimized_cuda_graphs.cu",
              "technique": "graphs",
              "status": "success",
              "time_ms": 265.3845236000052,
              "speedup": 4.956266900033817
            },
            {
              "file": "optimized_cuda_graphs_conditional_enhanced.cu",
              "technique": "graphs_conditional_enhanced",
              "status": "success",
              "time_ms": 349.3623938500036,
              "speedup": 3.764905877833752
            }
          ],
          "best_speedup": 4.956266900033817,
          "status": "success",
          "error": null
        },
        {
          "example": "cuda",
          "baseline_file": "baseline_cuda_graphs_conditional.cu",
          "type": "cuda",
          "baseline_time_ms": 984.3166960999952,
          "optimizations": [
            {
              "file": "optimized_cuda_graphs_conditional.cu",
              "technique": "graphs_conditional",
              "status": "success",
              "time_ms": 800.2097140000046,
              "speedup": 1.2300734156046367
            },
            {
              "file": "optimized_cuda_graphs.cu",
              "technique": "graphs",
              "status": "success",
              "time_ms": 274.4646110999838,
              "speedup": 3.5863155259073514
            },
            {
              "file": "optimized_cuda_graphs_conditional_enhanced.cu",
              "technique": "graphs_conditional_enhanced",
              "status": "success",
              "time_ms": 550.9844245999716,
              "speedup": 1.7864691852489907
            }
          ],
          "best_speedup": 3.5863155259073514,
          "status": "success",
          "error": null
        },
        {
          "example": "cuda",
          "baseline_file": "baseline_cuda_graphs.cu",
          "type": "cuda",
          "baseline_time_ms": 664.8658384500209,
          "optimizations": [
            {
              "file": "optimized_cuda_graphs_conditional.cu",
              "technique": "graphs_conditional",
              "status": "success",
              "time_ms": 575.2169391999928,
              "speedup": 1.1558523282967137
            },
            {
              "file": "optimized_cuda_graphs.cu",
              "technique": "graphs",
              "status": "success",
              "time_ms": 469.179144050031,
              "speedup": 1.4170831054227824
            },
            {
              "file": "optimized_cuda_graphs_conditional_enhanced.cu",
              "technique": "graphs_conditional_enhanced",
              "status": "success",
              "time_ms": 705.4042472499987,
              "speedup": 0.9425316632866675
            }
          ],
          "best_speedup": 1.4170831054227824,
          "status": "success",
          "error": null
        },
        {
          "example": "uneven",
          "baseline_file": "baseline_uneven_partition.cu",
          "type": "cuda",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline executable not found for baseline_uneven_partition.cu"
        },
        {
          "example": "dynamic",
          "baseline_file": "baseline_dynamic_parallelism.cu",
          "type": "cuda",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline executable not found for baseline_dynamic_parallelism.cu"
        },
        {
          "example": "graph",
          "baseline_file": "baseline_graph_bandwidth.cu",
          "type": "cuda",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline executable not found for baseline_graph_bandwidth.cu"
        },
        {
          "example": "work",
          "baseline_file": "baseline_work_queue.cu",
          "type": "cuda",
          "baseline_time_ms": 502.6888316999816,
          "optimizations": [
            {
              "file": "optimized_work_queue.cu",
              "technique": "queue",
              "status": "success",
              "time_ms": 445.0155656999982,
              "speedup": 1.1295983117113326
            }
          ],
          "best_speedup": 1.1295983117113326,
          "status": "success",
          "error": null
        },
        {
          "example": "kernel",
          "baseline_file": "baseline_kernel_fusion.cu",
          "type": "cuda",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline executable not found for baseline_kernel_fusion.cu"
        }
      ],
      "summary": {
        "total_benchmarks": 22,
        "successful": 17,
        "failed": 5,
        "skipped_hardware": 0,
        "total_speedups": 15,
        "average_speedup": 51.97735573974634,
        "max_speedup": 378.71483298763326,
        "min_speedup": 1.001467290492898
      }
    },
    {
      "chapter": "ch13",
      "status": "completed",
      "benchmarks": [
        {
          "example": "occupancy",
          "baseline_file": "baseline_occupancy.py",
          "baseline_time_ms": 12.510057830810547,
          "optimizations": [
            {
              "file": "optimized_occupancy.py",
              "technique": "optimized_occupancy",
              "status": "success",
              "time_ms": 0.926886397600174,
              "speedup": 13.496862035305154
            }
          ],
          "best_speedup": 13.496862035305154,
          "status": "success",
          "error": null
        },
        {
          "example": "dataloader",
          "baseline_file": "baseline_dataloader_default.py",
          "baseline_time_ms": 3.6106323194503784,
          "optimizations": [
            {
              "file": "optimized_dataloader_tuned.py",
              "technique": "tuned",
              "status": "success",
              "time_ms": 7.367520942687988,
              "speedup": 0.4900742525929033
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "continuous",
          "baseline_file": "baseline_continuous_batching.py",
          "baseline_time_ms": 117.76627578735352,
          "optimizations": [
            {
              "file": "optimized_continuous_batching.py",
              "technique": "batching",
              "status": "success",
              "time_ms": 0.011676800064742565,
              "speedup": 10085.49218402241
            }
          ],
          "best_speedup": 10085.49218402241,
          "status": "success",
          "error": null
        },
        {
          "example": "paged",
          "baseline_file": "baseline_paged_attention.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: Benchmark execution failed: not enough values to unpack (expected 3, got 2)"
        },
        {
          "example": "autograd",
          "baseline_file": "baseline_autograd_standard.py",
          "baseline_time_ms": 1.132054398059845,
          "optimizations": [
            {
              "file": "optimized_autograd_compiled.py",
              "technique": "compiled",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: "
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "bandwidth",
          "baseline_file": "baseline_bandwidth_naive.py",
          "baseline_time_ms": 87.39692535400391,
          "optimizations": [
            {
              "file": "optimized_bandwidth_coalesced.py",
              "technique": "coalesced",
              "status": "success",
              "time_ms": 0.996258237361908,
              "speedup": 87.72517212548324
            }
          ],
          "best_speedup": 87.72517212548324,
          "status": "success",
          "error": null
        },
        {
          "example": "precision",
          "baseline_file": "baseline_precision_bf16.py",
          "baseline_time_ms": 29.62331403096517,
          "optimizations": [
            {
              "file": "optimized_precision_mixed.py",
              "technique": "mixed",
              "status": "success",
              "time_ms": 2.8979091215133668,
              "speedup": 10.22230607959682
            },
            {
              "file": "optimized_precision_fp8.py",
              "technique": "fp8",
              "status": "success",
              "time_ms": 11.641550890604655,
              "speedup": 2.5446192100463816
            }
          ],
          "best_speedup": 10.22230607959682,
          "status": "success",
          "error": null
        },
        {
          "example": "shared",
          "baseline_file": "baseline_shared_memory.py",
          "baseline_time_ms": 0.5935168087482452,
          "optimizations": [
            {
              "file": "optimized_shared_memory.py",
              "technique": "memory",
              "status": "success",
              "time_ms": 0.10473919957876206,
              "speedup": 5.666615852853934
            }
          ],
          "best_speedup": 5.666615852853934,
          "status": "success",
          "error": null
        },
        {
          "example": "training",
          "baseline_file": "baseline_training_standard.py",
          "baseline_time_ms": 90.7858829498291,
          "optimizations": [
            {
              "file": "optimized_training_checkpoint.py",
              "technique": "checkpoint",
              "status": "success",
              "time_ms": 109.52615356445312,
              "speedup": 0.8288968433133563
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "arithmetic",
          "baseline_file": "baseline_arithmetic_intensity.py",
          "baseline_time_ms": 1.327986558675766,
          "optimizations": [
            {
              "file": "optimized_arithmetic_intensity.py",
              "technique": "intensity",
              "status": "success",
              "time_ms": 16.628033905029298,
              "speedup": 0.07986431626616448
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "warp",
          "baseline_file": "baseline_warp_specialization.py",
          "baseline_time_ms": 0.045081600174307825,
          "optimizations": [
            {
              "file": "optimized_warp_specialization.py",
              "technique": "specialization",
              "status": "success",
              "time_ms": 0.046563200280070306,
              "speedup": 0.968180878959116
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "memory",
          "baseline_file": "baseline_memory_profiling.py",
          "baseline_time_ms": 2.2224140620231627,
          "optimizations": [
            {
              "file": "optimized_memory_profiling.py",
              "technique": "profiling",
              "status": "success",
              "time_ms": 1.6392012810707093,
              "speedup": 1.3557908279399982
            }
          ],
          "best_speedup": 1.3557908279399982,
          "status": "success",
          "error": null
        },
        {
          "example": "tiling",
          "baseline_file": "baseline_tiling.py",
          "baseline_time_ms": 0.055900799855589864,
          "optimizations": [
            {
              "file": "optimized_tiling.py",
              "technique": "optimized_tiling",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: The size of tensor a (16384) must match the size of tensor b (2048) at non-singleton dimension 1\nException raised from infer_size_impl at /pytorch/aten/src/ATen/ExpandUtils.cpp:31 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xeeeb464ac700 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xeeeb4644a860 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #2: at::infer_size_dimvector(c10::ArrayRef<long>, c10::ArrayRef<long>) + 0x340 (0xeeeb62d1e7a0 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: at::TensorIteratorBase::compute_shape(at::TensorIteratorConfig const&) + 0x100 (0xeeeb62d28730 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: at::TensorIteratorBase::build(at::TensorIteratorConfig&) + 0x54 (0xeeeb62d2c684 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: at::TensorIteratorBase::build_borrowing_binary_op(at::TensorBase const&, at::TensorBase const&, at::TensorBase const&) + 0xa0 (0xeeeb62d2d3c0 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #6: at::meta::structured_add_Tensor::meta(at::Tensor const&, at::Tensor const&, c10::Scalar const&) + 0x44 (0xeeeb62d35c54 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #7: <unknown function> + 0xa5bb74 (0xeeeb46c7bb74 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\nframe #8: <unknown function> + 0xa5bc30 (0xeeeb46c7bc30 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\nframe #9: at::_ops::add_Tensor::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, c10::Scalar const&) + 0x8c (0xeeeb62d6909c in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #10: <unknown function> + 0x1277004 (0xeeeb62d87004 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: <unknown function> + 0x1277584 (0xeeeb62d87584 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: at::_ops::add_Tensor::call(at::Tensor const&, at::Tensor const&, c10::Scalar const&) + 0x188 (0xeeeb62d69bd8 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: <unknown function> + 0x5dd850 (0xeeeb6c0ed850 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #14: <unknown function> + 0x5ddac0 (0xeeeb6c0edac0 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #15: python() [0x4e4d2c]\nframe #16: python() [0x560a70]\nframe #17: python() [0x64fdbc]\n<omitting python frames>\nframe #22: python() [0x514c68]\nframe #23: python() [0x514548]\nframe #24: python() [0x64013c]\nframe #25: python() [0x5f6de4]\nframe #26: <unknown function> + 0x8595c (0xeeeb7ae3595c in /lib/aarch64-linux-gnu/libc.so.6)\nframe #27: <unknown function> + 0xebb0c (0xeeeb7ae9bb0c in /lib/aarch64-linux-gnu/libc.so.6)\n"
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "precision",
          "baseline_file": "baseline_precision_fp32.py",
          "baseline_time_ms": 1.2772319984436036,
          "optimizations": [
            {
              "file": "optimized_precision_mixed.py",
              "technique": "mixed",
              "status": "success",
              "time_ms": 2.2992627167701722,
              "speedup": 0.5554963289439847
            },
            {
              "file": "optimized_precision_fp8.py",
              "technique": "fp8",
              "status": "success",
              "time_ms": 11.58359473546346,
              "speedup": 0.11026214466337694
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "attention",
          "baseline_file": "baseline_attention_standard.py",
          "baseline_time_ms": 0.6095942384004593,
          "optimizations": [
            {
              "file": "optimized_attention_flex.py",
              "technique": "flex",
              "status": "success",
              "time_ms": 0.3128819185495377,
              "speedup": 1.948320443784111
            }
          ],
          "best_speedup": 1.948320443784111,
          "status": "success",
          "error": null
        },
        {
          "example": "kv",
          "baseline_file": "baseline_kv_cache_naive.py",
          "baseline_time_ms": 21.868641662597657,
          "optimizations": [
            {
              "file": "optimized_kv_cache.py",
              "technique": "cache_optimized",
              "status": "success",
              "time_ms": 29.742095756530762,
              "speedup": 0.7352757465921259
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "matmul",
          "baseline_file": "baseline_matmul_pytorch.py",
          "baseline_time_ms": 0.363050879240036,
          "optimizations": [
            {
              "file": "optimized_matmul_cutlass.py",
              "technique": "cutlass",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: "
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 17,
        "successful": 13,
        "failed": 4,
        "skipped_hardware": 0,
        "total_speedups": 7,
        "average_speedup": 1457.986750198196,
        "max_speedup": 10085.49218402241,
        "min_speedup": 1.3557908279399982
      }
    },
    {
      "chapter": "ch14",
      "status": "completed",
      "benchmarks": [
        {
          "example": "roofline",
          "baseline_file": "baseline_roofline_quantization.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: Benchmark execution failed: Could not run 'quantized::linear_dynamic' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear_dynamic' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMTIA, AutogradMAIA, AutogradMeta, Tracer, AutocastCPU, AutocastMTIA, AutocastMAIA, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at /pytorch/aten/src/ATen/native/quantized/cpu/qlinear_dynamic.cpp:1027 [kernel]\nMeta: registered at /pytorch/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:479 [backend fallback]\nFunctionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:387 [backend fallback]\nNamed: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:115 [backend fallback]\nADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:104 [backend fallback]\nAutogradOther: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradCPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradCUDA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:75 [backend fallback]\nAutogradXLA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:87 [backend fallback]\nAutogradMPS: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:95 [backend fallback]\nAutogradXPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:71 [backend fallback]\nAutogradHPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:108 [backend fallback]\nAutogradLazy: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:91 [backend fallback]\nAutogradMTIA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:79 [backend fallback]\nAutogradMAIA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:83 [backend fallback]\nAutogradMeta: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:99 [backend fallback]\nTracer: registered at /pytorch/torch/csrc/autograd/TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nAutocastMTIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:468 [backend fallback]\nAutocastMAIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:506 [backend fallback]\nAutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:544 [backend fallback]\nAutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:475 [backend fallback]\nPreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n\nException raised from reportError at /pytorch/aten/src/ATen/core/dispatch/OperatorEntry.cpp:650 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xeeeb464ac700 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #1: c10::impl::OperatorEntry::reportError(c10::DispatchKey) const + 0x448 (0xeeeb630d2ed8 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #2: <unknown function> + 0x1348c28 (0xeeeb62e58c28 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: <unknown function> + 0x54dfd24 (0xeeeb66fefd24 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: <unknown function> + 0x5c4c7fc (0xeeeb6775c7fc in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: <unknown function> + 0xd4b67c (0xeeeb6c85b67c in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #6: <unknown function> + 0xd4ba14 (0xeeeb6c85ba14 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #7: torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 0x3c (0xeeeb6c85baac in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #8: <unknown function> + 0xc434e0 (0xeeeb6c7534e0 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #9: <unknown function> + 0x5d6d4c (0xeeeb6c0e6d4c in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #10: python() [0x4d9630]\n<omitting python frames>\nframe #16: python() [0x616798]\nframe #19: python() [0x514354]\nframe #21: python() [0x514354]\nframe #26: python() [0x616798]\nframe #29: python() [0x514354]\nframe #31: python() [0x514354]\nframe #36: python() [0x616798]\nframe #41: python() [0x514c68]\nframe #42: python() [0x514548]\nframe #43: python() [0x64013c]\nframe #44: python() [0x5f6de4]\nframe #45: <unknown function> + 0x8595c (0xeeeb7ae3595c in /lib/aarch64-linux-gnu/libc.so.6)\nframe #46: <unknown function> + 0xebb0c (0xeeeb7ae9bb0c in /lib/aarch64-linux-gnu/libc.so.6)\n"
        },
        {
          "example": "flex",
          "baseline_file": "baseline_flex_attention.py",
          "baseline_time_ms": 0.06835392072796821,
          "optimizations": [
            {
              "file": "optimized_flex_attention.py",
              "technique": "attention",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: "
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "model",
          "baseline_file": "baseline_model_eager.py",
          "baseline_time_ms": 60.156014633178714,
          "optimizations": [
            {
              "file": "optimized_model_compiled.py",
              "technique": "compiled",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: "
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "nccl",
          "baseline_file": "baseline_nccl_quantization.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: Benchmark execution failed: Could not run 'quantized::linear_dynamic' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::linear_dynamic' is only available for these backends: [CPU, Meta, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMTIA, AutogradMAIA, AutogradMeta, Tracer, AutocastCPU, AutocastMTIA, AutocastMAIA, AutocastXPU, AutocastMPS, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nCPU: registered at /pytorch/aten/src/ATen/native/quantized/cpu/qlinear_dynamic.cpp:1027 [kernel]\nMeta: registered at /pytorch/aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:194 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:479 [backend fallback]\nFunctionalize: registered at /pytorch/aten/src/ATen/FunctionalizeFallbackKernel.cpp:387 [backend fallback]\nNamed: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /pytorch/aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at /pytorch/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /pytorch/aten/src/ATen/ZeroTensorFallback.cpp:115 [backend fallback]\nADInplaceOrView: fallthrough registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:104 [backend fallback]\nAutogradOther: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradCPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:67 [backend fallback]\nAutogradCUDA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:75 [backend fallback]\nAutogradXLA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:87 [backend fallback]\nAutogradMPS: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:95 [backend fallback]\nAutogradXPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:71 [backend fallback]\nAutogradHPU: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:108 [backend fallback]\nAutogradLazy: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:91 [backend fallback]\nAutogradMTIA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:79 [backend fallback]\nAutogradMAIA: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:83 [backend fallback]\nAutogradMeta: registered at /pytorch/aten/src/ATen/core/VariableFallbackKernel.cpp:99 [backend fallback]\nTracer: registered at /pytorch/torch/csrc/autograd/TraceTypeManual.cpp:294 [backend fallback]\nAutocastCPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:324 [backend fallback]\nAutocastMTIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:468 [backend fallback]\nAutocastMAIA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:506 [backend fallback]\nAutocastXPU: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:544 [backend fallback]\nAutocastMPS: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:209 [backend fallback]\nAutocastCUDA: fallthrough registered at /pytorch/aten/src/ATen/autocast_mode.cpp:165 [backend fallback]\nFuncTorchBatched: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at /pytorch/aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at /pytorch/aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at /pytorch/aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at /pytorch/aten/src/ATen/functorch/TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:202 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at /pytorch/aten/src/ATen/functorch/DynamicLayer.cpp:475 [backend fallback]\nPreDispatch: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:206 [backend fallback]\nPythonDispatcher: registered at /pytorch/aten/src/ATen/core/PythonFallbackKernel.cpp:198 [backend fallback]\n\nException raised from reportError at /pytorch/aten/src/ATen/core/dispatch/OperatorEntry.cpp:650 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xeeeb464ac700 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #1: c10::impl::OperatorEntry::reportError(c10::DispatchKey) const + 0x448 (0xeeeb630d2ed8 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #2: <unknown function> + 0x1348c28 (0xeeeb62e58c28 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: <unknown function> + 0x54dfd24 (0xeeeb66fefd24 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: <unknown function> + 0x5c4c7fc (0xeeeb6775c7fc in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: <unknown function> + 0xd4b67c (0xeeeb6c85b67c in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #6: <unknown function> + 0xd4ba14 (0xeeeb6c85ba14 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #7: torch::jit::_get_operation_for_overload_or_packet(std::vector<std::shared_ptr<torch::jit::Operator>, std::allocator<std::shared_ptr<torch::jit::Operator> > > const&, c10::Symbol, pybind11::args const&, pybind11::kwargs const&, bool, std::optional<c10::DispatchKey>) + 0x3c (0xeeeb6c85baac in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #8: <unknown function> + 0xc434e0 (0xeeeb6c7534e0 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #9: <unknown function> + 0x5d6d4c (0xeeeb6c0e6d4c in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #10: python() [0x4d9630]\n<omitting python frames>\nframe #16: python() [0x616798]\nframe #19: python() [0x514354]\nframe #21: python() [0x514354]\nframe #26: python() [0x616798]\nframe #29: python() [0x514354]\nframe #31: python() [0x514354]\nframe #36: python() [0x616798]\nframe #41: python() [0x514c68]\nframe #42: python() [0x514548]\nframe #43: python() [0x64013c]\nframe #44: python() [0x5f6de4]\nframe #45: <unknown function> + 0x8595c (0xeeeb7ae3595c in /lib/aarch64-linux-gnu/libc.so.6)\nframe #46: <unknown function> + 0xebb0c (0xeeeb7ae9bb0c in /lib/aarch64-linux-gnu/libc.so.6)\n"
        }
      ],
      "summary": {
        "total_benchmarks": 4,
        "successful": 0,
        "failed": 4,
        "skipped_hardware": 0,
        "total_speedups": 0,
        "average_speedup": 1.0,
        "max_speedup": 1.0,
        "min_speedup": 1.0
      }
    },
    {
      "chapter": "ch15",
      "status": "completed",
      "benchmarks": [
        {
          "example": "nvlink",
          "baseline_file": "baseline_nvlink.py",
          "baseline_time_ms": 19.74194797515869,
          "optimizations": [
            {
              "file": "optimized_nvlink.py",
              "technique": "optimized_nvlink",
              "status": "success",
              "time_ms": 5.46573245048523,
              "speedup": 3.6119492042472854
            }
          ],
          "best_speedup": 3.6119492042472854,
          "status": "success",
          "error": null
        },
        {
          "example": "flash",
          "baseline_file": "baseline_flash_attention.py",
          "baseline_time_ms": 1.077749124765396,
          "optimizations": [
            {
              "file": "optimized_flash_attention.py",
              "technique": "attention",
              "status": "success",
              "time_ms": 1.0177728009223939,
              "speedup": 1.0589289906240829
            }
          ],
          "best_speedup": 1.0589289906240829,
          "status": "success",
          "error": null
        },
        {
          "example": "continuous",
          "baseline_file": "baseline_continuous_batching.py",
          "baseline_time_ms": 3.2534783840179444,
          "optimizations": [
            {
              "file": "optimized_continuous_batching.py",
              "technique": "batching",
              "status": "success",
              "time_ms": 0.018943999707698823,
              "speedup": 171.74189369817896
            }
          ],
          "best_speedup": 171.74189369817896,
          "status": "success",
          "error": null
        },
        {
          "example": "roofline",
          "baseline_file": "baseline_roofline.py",
          "baseline_time_ms": 0.14197887949645518,
          "optimizations": [
            {
              "file": "optimized_roofline.py",
              "technique": "optimized_roofline",
              "status": "success",
              "time_ms": 0.4320704011619091,
              "speedup": 0.328601262929954
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "kv",
          "baseline_file": "baseline_kv_cache_management.py",
          "baseline_time_ms": 3.107862424850464,
          "optimizations": [
            {
              "file": "optimized_kv_cache_management.py",
              "technique": "cache_management",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: not enough values to unpack (expected 3, got 2)"
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "inference",
          "baseline_file": "baseline_inference_monolithic.py",
          "baseline_time_ms": 3.9436895728111265,
          "optimizations": [
            {
              "file": "optimized_inference_disaggregated.py",
              "technique": "disaggregated",
              "status": "success",
              "time_ms": 3.91283997297287,
              "speedup": 1.007884196658014
            }
          ],
          "best_speedup": 1.007884196658014,
          "status": "success",
          "error": null
        },
        {
          "example": "nccl",
          "baseline_file": "baseline_nccl.py",
          "baseline_time_ms": 3.207456005811691,
          "optimizations": [
            {
              "file": "optimized_nccl.py",
              "technique": "optimized_nccl",
              "status": "success",
              "time_ms": 0.16220672100782393,
              "speedup": 19.773878578415882
            }
          ],
          "best_speedup": 19.773878578415882,
          "status": "success",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 7,
        "successful": 6,
        "failed": 1,
        "skipped_hardware": 0,
        "total_speedups": 5,
        "average_speedup": 39.43890693362484,
        "max_speedup": 171.74189369817896,
        "min_speedup": 1.007884196658014
      }
    },
    {
      "chapter": "ch16",
      "status": "completed",
      "benchmarks": [
        {
          "example": "occupancy",
          "baseline_file": "baseline_occupancy.py",
          "baseline_time_ms": 0.6760800004005432,
          "optimizations": [
            {
              "file": "optimized_occupancy.py",
              "technique": "optimized_occupancy",
              "status": "success",
              "time_ms": 0.11034240052103997,
              "speedup": 6.127109771113136
            }
          ],
          "best_speedup": 6.127109771113136,
          "status": "success",
          "error": null
        },
        {
          "example": "moe",
          "baseline_file": "baseline_moe_dense.py",
          "baseline_time_ms": 259.91247329711916,
          "optimizations": [
            {
              "file": "optimized_moe_sparse.py",
              "technique": "sparse",
              "status": "success",
              "time_ms": 148.08245239257812,
              "speedup": 1.7551875262578103
            }
          ],
          "best_speedup": 1.7551875262578103,
          "status": "success",
          "error": null
        },
        {
          "example": "paged",
          "baseline_file": "baseline_paged_attention.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: Benchmark execution failed: not enough values to unpack (expected 3, got 2)"
        },
        {
          "example": "shared",
          "baseline_file": "baseline_shared_memory.py",
          "baseline_time_ms": 0.21846719831228256,
          "optimizations": [
            {
              "file": "optimized_shared_memory.py",
              "technique": "memory",
              "status": "success",
              "time_ms": 0.22518719881772994,
              "speedup": 0.9701581593415234
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "coalescing",
          "baseline_file": "baseline_coalescing.py",
          "baseline_time_ms": 0.17463359981775284,
          "optimizations": [
            {
              "file": "optimized_coalescing.py",
              "technique": "optimized_coalescing",
              "status": "success",
              "time_ms": 0.45816320180892944,
              "speedup": 0.3811602484186003
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "tiling",
          "baseline_file": "baseline_tiling.py",
          "baseline_time_ms": 0.08943680040538311,
          "optimizations": [
            {
              "file": "optimized_tiling.py",
              "technique": "optimized_tiling",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: The size of tensor a (16384) must match the size of tensor b (2048) at non-singleton dimension 1\nException raised from infer_size_impl at /pytorch/aten/src/ATen/ExpandUtils.cpp:31 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xeeeb464ac700 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xeeeb4644a860 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #2: at::infer_size_dimvector(c10::ArrayRef<long>, c10::ArrayRef<long>) + 0x340 (0xeeeb62d1e7a0 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: at::TensorIteratorBase::compute_shape(at::TensorIteratorConfig const&) + 0x100 (0xeeeb62d28730 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: at::TensorIteratorBase::build(at::TensorIteratorConfig&) + 0x54 (0xeeeb62d2c684 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #5: at::TensorIteratorBase::build_borrowing_binary_op(at::TensorBase const&, at::TensorBase const&, at::TensorBase const&) + 0xa0 (0xeeeb62d2d3c0 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #6: at::meta::structured_add_Tensor::meta(at::Tensor const&, at::Tensor const&, c10::Scalar const&) + 0x44 (0xeeeb62d35c54 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #7: <unknown function> + 0xa5bb74 (0xeeeb46c7bb74 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\nframe #8: <unknown function> + 0xa5bc30 (0xeeeb46c7bc30 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\nframe #9: at::_ops::add_Tensor::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&, c10::Scalar const&) + 0x8c (0xeeeb62d6909c in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #10: <unknown function> + 0x1277004 (0xeeeb62d87004 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: <unknown function> + 0x1277584 (0xeeeb62d87584 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: at::_ops::add_Tensor::call(at::Tensor const&, at::Tensor const&, c10::Scalar const&) + 0x188 (0xeeeb62d69bd8 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: <unknown function> + 0x5dd850 (0xeeeb6c0ed850 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #14: <unknown function> + 0x5ddac0 (0xeeeb6c0edac0 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #15: python() [0x4e4d2c]\nframe #16: python() [0x560a70]\nframe #17: python() [0x64fdbc]\n<omitting python frames>\nframe #22: python() [0x514c68]\nframe #23: python() [0x514548]\nframe #24: python() [0x64013c]\nframe #25: python() [0x5f6de4]\nframe #26: <unknown function> + 0x8595c (0xeeeb7ae3595c in /lib/aarch64-linux-gnu/libc.so.6)\nframe #27: <unknown function> + 0xebb0c (0xeeeb7ae9bb0c in /lib/aarch64-linux-gnu/libc.so.6)\n"
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "disaggregated",
          "baseline_file": "baseline_disaggregated.py",
          "baseline_time_ms": 0.6510591983795166,
          "optimizations": [
            {
              "file": "optimized_disaggregated.py",
              "technique": "optimized_disaggregated",
              "status": "success",
              "time_ms": 0.7215616047382355,
              "speedup": 0.9022919098026352
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "regional",
          "baseline_file": "baseline_regional_compilation.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Failed to load baseline"
        }
      ],
      "summary": {
        "total_benchmarks": 8,
        "successful": 5,
        "failed": 3,
        "skipped_hardware": 0,
        "total_speedups": 2,
        "average_speedup": 3.941148648685473,
        "max_speedup": 6.127109771113136,
        "min_speedup": 1.7551875262578103
      }
    },
    {
      "chapter": "ch17",
      "status": "completed",
      "benchmarks": [
        {
          "example": "continuous",
          "baseline_file": "baseline_continuous_batching.py",
          "baseline_time_ms": 5.137603211402893,
          "optimizations": [
            {
              "file": "optimized_continuous_batching.py",
              "technique": "batching",
              "status": "success",
              "time_ms": 0.017283199820667505,
              "speedup": 297.2599556049379
            }
          ],
          "best_speedup": 297.2599556049379,
          "status": "success",
          "error": null
        },
        {
          "example": "paged",
          "baseline_file": "baseline_paged_attention.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: Benchmark execution failed: not enough values to unpack (expected 3, got 2)"
        },
        {
          "example": "inference",
          "baseline_file": "baseline_inference_full.py",
          "baseline_time_ms": 3.4220857715606687,
          "optimizations": [
            {
              "file": "optimized_inference_early_exit.py",
              "technique": "early_exit",
              "status": "success",
              "time_ms": 1.577426552772522,
              "speedup": 2.169410528525674
            }
          ],
          "best_speedup": 2.169410528525674,
          "status": "success",
          "error": null
        },
        {
          "example": "speculative",
          "baseline_file": "baseline_speculative_decoding.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: Benchmark execution failed: TransformerDecoder.forward() missing 1 required positional argument: 'memory'"
        },
        {
          "example": "moe",
          "baseline_file": "baseline_moe.py",
          "baseline_time_ms": 0.07637440003454685,
          "optimizations": [
            {
              "file": "optimized_moe.py",
              "technique": "optimized_moe",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: not enough values to unpack (expected 3, got 2)"
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "routing",
          "baseline_file": "baseline_routing_static.py",
          "baseline_time_ms": 3.273065586090088,
          "optimizations": [
            {
              "file": "optimized_routing_dynamic.py",
              "technique": "dynamic",
              "status": "success",
              "time_ms": 1.2968332731723786,
              "speedup": 2.5238908144941026
            }
          ],
          "best_speedup": 2.5238908144941026,
          "status": "success",
          "error": null
        },
        {
          "example": "kv",
          "baseline_file": "baseline_kv_cache_management.py",
          "baseline_time_ms": 3.0481664180755614,
          "optimizations": [
            {
              "file": "optimized_kv_cache_management.py",
              "technique": "cache_management",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: not enough values to unpack (expected 3, got 2)"
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "attention",
          "baseline_file": "baseline_attention.py",
          "baseline_time_ms": 0.14886719971895218,
          "optimizations": [
            {
              "file": "optimized_attention.py",
              "technique": "optimized_attention",
              "status": "success",
              "time_ms": 0.16858367949724198,
              "speedup": 0.8830463314296544
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 8,
        "successful": 4,
        "failed": 4,
        "skipped_hardware": 0,
        "total_speedups": 3,
        "average_speedup": 100.65108564931921,
        "max_speedup": 297.2599556049379,
        "min_speedup": 2.169410528525674
      }
    },
    {
      "chapter": "ch18",
      "status": "completed",
      "benchmarks": [
        {
          "example": "streams",
          "baseline_file": "baseline_streams.py",
          "baseline_time_ms": 0.3468915209174156,
          "optimizations": [
            {
              "file": "optimized_streams.py",
              "technique": "optimized_streams",
              "status": "success",
              "time_ms": 0.3668313604593277,
              "speedup": 0.9456430346714512
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "ai",
          "baseline_file": "baseline_ai_optimization.py",
          "baseline_time_ms": 0.1433043199777603,
          "optimizations": [
            {
              "file": "optimized_ai_optimization.py",
              "technique": "optimization",
              "status": "success",
              "time_ms": 2.4272921466827393,
              "speedup": 0.05903876060968073
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "distributed",
          "baseline_file": "baseline_distributed.py",
          "baseline_time_ms": 0.15175296023488044,
          "optimizations": [
            {
              "file": "optimized_distributed.py",
              "technique": "optimized_distributed",
              "status": "success",
              "time_ms": 0.16252351954579353,
              "speedup": 0.9337292267542956
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "quantization",
          "baseline_file": "baseline_quantization.py",
          "baseline_time_ms": 0.16801344215869904,
          "optimizations": [
            {
              "file": "optimized_quantization.py",
              "technique": "optimized_quantization",
              "status": "success",
              "time_ms": 0.162929280847311,
              "speedup": 1.0312047121606867
            }
          ],
          "best_speedup": 1.0312047121606867,
          "status": "success",
          "error": null
        },
        {
          "example": "speculative",
          "baseline_file": "baseline_speculative_decoding.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: Benchmark execution failed: TransformerDecoder.forward() missing 1 required positional argument: 'memory'"
        },
        {
          "example": "shared",
          "baseline_file": "baseline_shared_memory.py",
          "baseline_time_ms": 0.14655040010809897,
          "optimizations": [
            {
              "file": "optimized_shared_memory.py",
              "technique": "memory",
              "status": "success",
              "time_ms": 0.17927807867527007,
              "speedup": 0.8174474045627664
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "roofline",
          "baseline_file": "baseline_roofline.py",
          "baseline_time_ms": 0.1965561591088772,
          "optimizations": [
            {
              "file": "optimized_roofline.py",
              "technique": "optimized_roofline",
              "status": "success",
              "time_ms": 0.38129408061504366,
              "speedup": 0.5154975361585045
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "warp",
          "baseline_file": "baseline_warp_specialization.py",
          "baseline_time_ms": 0.1718764804303646,
          "optimizations": [
            {
              "file": "optimized_warp_specialization.py",
              "technique": "specialization",
              "status": "success",
              "time_ms": 0.15697600007057189,
              "speedup": 1.094922028546363
            }
          ],
          "best_speedup": 1.094922028546363,
          "status": "success",
          "error": null
        },
        {
          "example": "disaggregated",
          "baseline_file": "baseline_disaggregated.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: Benchmark execution failed: TransformerDecoder.forward() missing 1 required positional argument: 'memory'"
        },
        {
          "example": "nccl",
          "baseline_file": "baseline_nccl.py",
          "baseline_time_ms": 3.571644160747528,
          "optimizations": [
            {
              "file": "optimized_nccl.py",
              "technique": "optimized_nccl",
              "status": "success",
              "time_ms": 0.3154707193374634,
              "speedup": 11.32163443963524
            }
          ],
          "best_speedup": 11.32163443963524,
          "status": "success",
          "error": null
        },
        {
          "example": "attention",
          "baseline_file": "baseline_attention.py",
          "baseline_time_ms": 8.772815990447999,
          "optimizations": [
            {
              "file": "optimized_attention_flash.py",
              "technique": "flash",
              "status": "success",
              "time_ms": 1.5139999985694885,
              "speedup": 5.794462350552869
            }
          ],
          "best_speedup": 5.794462350552869,
          "status": "success",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 11,
        "successful": 9,
        "failed": 2,
        "skipped_hardware": 0,
        "total_speedups": 4,
        "average_speedup": 4.81055588272379,
        "max_speedup": 11.32163443963524,
        "min_speedup": 1.0312047121606867
      }
    },
    {
      "chapter": "ch19",
      "status": "completed",
      "benchmarks": [
        {
          "example": "memory",
          "baseline_file": "baseline_memory_coalescing.py",
          "baseline_time_ms": 2.252606415748596,
          "optimizations": [
            {
              "file": "optimized_memory_double_buffering.py",
              "technique": "double_buffering",
              "status": "success",
              "time_ms": 2.134742420911789,
              "speedup": 1.0552122793280443
            },
            {
              "file": "optimized_memory_flash_attention.py",
              "technique": "flash_attention",
              "status": "success",
              "time_ms": 1.0739935994148255,
              "speedup": 2.0974113970287602
            },
            {
              "file": "optimized_memory_moe.py",
              "technique": "moe",
              "status": "success",
              "time_ms": 22.52594233751297,
              "speedup": 0.10000054079856535
            },
            {
              "file": "optimized_memory_coalescing.py",
              "technique": "coalescing",
              "status": "success",
              "time_ms": 1.7626543998718263,
              "speedup": 1.2779626090698195
            }
          ],
          "best_speedup": 2.0974113970287602,
          "status": "success",
          "error": null
        },
        {
          "example": "continuous",
          "baseline_file": "baseline_continuous_batching.py",
          "baseline_time_ms": 0.044062080159783364,
          "optimizations": [
            {
              "file": "optimized_continuous_batching.py",
              "technique": "batching",
              "status": "success",
              "time_ms": 0.49979712009429933,
              "speedup": 0.08815993207697943
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "vectorization",
          "baseline_file": "baseline_vectorization_memory.py",
          "baseline_time_ms": 0.08459872007369995,
          "optimizations": [
            {
              "file": "optimized_vectorization_memory.py",
              "technique": "memory",
              "status": "success",
              "time_ms": 0.09057888008654118,
              "speedup": 0.9339784284468119
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "disaggregated",
          "baseline_file": "baseline_disaggregated_memory.py",
          "baseline_time_ms": 0.056731199845671654,
          "optimizations": [
            {
              "file": "optimized_disaggregated_memory.py",
              "technique": "memory",
              "status": "success",
              "time_ms": 0.32991999983787534,
              "speedup": 0.171954412807801
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "precision",
          "baseline_file": "baseline_precision_bf16.py",
          "baseline_time_ms": 122.70818862915038,
          "optimizations": [
            {
              "file": "optimized_precision_fp8.py",
              "technique": "fp8",
              "status": "success",
              "time_ms": 183.0359619140625,
              "speedup": 0.6704048064978798
            },
            {
              "file": "optimized_precision_fp4.py",
              "technique": "fp4",
              "status": "failed",
              "error": "Benchmark failed: TIMEOUT: Benchmark exceeded timeout of 15 seconds"
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "triton",
          "baseline_file": "baseline_triton_memory.py",
          "baseline_time_ms": 18.42553315775469,
          "optimizations": [
            {
              "file": "optimized_triton_memory.py",
              "technique": "memory",
              "status": "success",
              "time_ms": 0.12571488004177808,
              "speedup": 146.56604812120443
            }
          ],
          "best_speedup": 146.56604812120443,
          "status": "success",
          "error": null
        },
        {
          "example": "cutlass",
          "baseline_file": "baseline_cutlass_memory.py",
          "baseline_time_ms": 0.03177728017792106,
          "optimizations": [
            {
              "file": "optimized_cutlass_memory.py",
              "technique": "memory",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: "
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "memory",
          "baseline_file": "baseline_memory_double_buffering.py",
          "baseline_time_ms": 3.0855647802352903,
          "optimizations": [
            {
              "file": "optimized_memory_double_buffering.py",
              "technique": "double_buffering",
              "status": "success",
              "time_ms": 2.663396787643433,
              "speedup": 1.1585073596808648
            },
            {
              "file": "optimized_memory_flash_attention.py",
              "technique": "flash_attention",
              "status": "success",
              "time_ms": 1.2108528017997742,
              "speedup": 2.5482575385290454
            },
            {
              "file": "optimized_memory_moe.py",
              "technique": "moe",
              "status": "success",
              "time_ms": 9.8382719039917,
              "speedup": 0.3136287358538422
            },
            {
              "file": "optimized_memory_coalescing.py",
              "technique": "coalescing",
              "status": "success",
              "time_ms": 1.531107211112976,
              "speedup": 2.0152506355138677
            }
          ],
          "best_speedup": 2.5482575385290454,
          "status": "success",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 8,
        "successful": 7,
        "failed": 1,
        "skipped_hardware": 0,
        "total_speedups": 5,
        "average_speedup": 30.68508733915423,
        "max_speedup": 146.56604812120443,
        "min_speedup": 1.0552122793280443
      }
    },
    {
      "chapter": "ch2",
      "status": "completed",
      "benchmarks": [
        {
          "example": "continuous",
          "baseline_file": "baseline_continuous_batching.py",
          "baseline_time_ms": 1.6120768189430237,
          "optimizations": [
            {
              "file": "optimized_continuous_batching.py",
              "technique": "batching",
              "status": "success",
              "time_ms": 0.020748799620196223,
              "speedup": 77.6949437293654
            }
          ],
          "best_speedup": 77.6949437293654,
          "status": "success",
          "error": null
        },
        {
          "example": "cutlass",
          "baseline_file": "baseline_cutlass.py",
          "baseline_time_ms": 0.3515027189254761,
          "optimizations": [
            {
              "file": "optimized_cutlass.py",
              "technique": "optimized_cutlass",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: "
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "speculative",
          "baseline_file": "baseline_speculative_decoding.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: Benchmark execution failed: TransformerDecoder.forward() missing 1 required positional argument: 'memory'"
        },
        {
          "example": "moe",
          "baseline_file": "baseline_moe.py",
          "baseline_time_ms": 0.08834432028234004,
          "optimizations": [
            {
              "file": "optimized_moe.py",
              "technique": "optimized_moe",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: not enough values to unpack (expected 3, got 2)"
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "memory",
          "baseline_file": "baseline_memory_transfer.py",
          "baseline_time_ms": 2.760015997886658,
          "optimizations": [
            {
              "file": "optimized_memory_transfer.py",
              "technique": "transfer",
              "status": "success",
              "time_ms": 0.4369267177581787,
              "speedup": 6.316885385375346
            }
          ],
          "best_speedup": 6.316885385375346,
          "status": "success",
          "error": null
        },
        {
          "example": "attention",
          "baseline_file": "baseline_attention.py",
          "baseline_time_ms": 0.1319289594888687,
          "optimizations": [
            {
              "file": "optimized_attention.py",
              "technique": "optimized_attention",
              "status": "success",
              "time_ms": 0.1708473591506481,
              "speedup": 0.7722036802016804
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "memory",
          "baseline_file": "baseline_memory_transfer.cu",
          "type": "cuda",
          "baseline_time_ms": 6206.0829509499645,
          "optimizations": [
            {
              "file": "optimized_memory_transfer_nvlink.cu",
              "technique": "transfer_nvlink",
              "status": "success",
              "time_ms": 21285.35510839999,
              "speedup": 0.29156586391649225
            },
            {
              "file": "optimized_memory_transfer_zero_copy.cu",
              "technique": "transfer_zero_copy",
              "status": "success",
              "time_ms": 1636.9316379500333,
              "speedup": 3.7912902451576924
            }
          ],
          "best_speedup": 3.7912902451576924,
          "status": "success",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 7,
        "successful": 4,
        "failed": 3,
        "skipped_hardware": 0,
        "total_speedups": 3,
        "average_speedup": 29.267706453299482,
        "max_speedup": 77.6949437293654,
        "min_speedup": 3.7912902451576924
      }
    },
    {
      "chapter": "ch20",
      "status": "completed",
      "benchmarks": [
        {
          "example": "occupancy",
          "baseline_file": "baseline_occupancy.py",
          "baseline_time_ms": 4.872047996520996,
          "optimizations": [
            {
              "file": "optimized_occupancy.py",
              "technique": "optimized_occupancy",
              "status": "success",
              "time_ms": 0.04589119963347912,
              "speedup": 106.16519148404826
            }
          ],
          "best_speedup": 106.16519148404826,
          "status": "success",
          "error": null
        },
        {
          "example": "nvlink",
          "baseline_file": "baseline_nvlink.py",
          "baseline_time_ms": 3.023203206062317,
          "optimizations": [
            {
              "file": "optimized_nvlink.py",
              "technique": "optimized_nvlink",
              "status": "success",
              "time_ms": 1.793504011631012,
              "speedup": 1.685640615497156
            }
          ],
          "best_speedup": 1.685640615497156,
          "status": "success",
          "error": null
        },
        {
          "example": "memory",
          "baseline_file": "baseline_memory_standard.py",
          "baseline_time_ms": 3.277784948348999,
          "optimizations": [
            {
              "file": "optimized_memory_hbm3e.py",
              "technique": "hbm3e",
              "status": "success",
              "time_ms": 2.4800694370269776,
              "speedup": 1.32165047454409
            }
          ],
          "best_speedup": 1.32165047454409,
          "status": "success",
          "error": null
        },
        {
          "example": "integrated",
          "baseline_file": "baseline_integrated_kv_cache.py",
          "baseline_time_ms": 45.097731018066405,
          "optimizations": [
            {
              "file": "optimized_integrated_kv_cache.py",
              "technique": "kv_cache",
              "status": "success",
              "time_ms": 135.88909835815429,
              "speedup": 0.3318715891337006
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "precision",
          "baseline_file": "baseline_precision_bf16.py",
          "baseline_time_ms": 11.390672664642334,
          "optimizations": [
            {
              "file": "optimized_precision_fp8.py",
              "technique": "fp8",
              "status": "success",
              "time_ms": 11.554965152740479,
              "speedup": 0.9857816543861078
            },
            {
              "file": "optimized_precision_fp4.py",
              "technique": "fp4",
              "status": "success",
              "time_ms": 12.918358383178711,
              "speedup": 0.8817430455772453
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "moe",
          "baseline_file": "baseline_moe.py",
          "baseline_time_ms": 0.7535871978849172,
          "optimizations": [
            {
              "file": "optimized_moe.py",
              "technique": "optimized_moe",
              "status": "success",
              "time_ms": 23.406848335266112,
              "speedup": 0.032195158745465066
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "batching",
          "baseline_file": "baseline_batching_static.py",
          "baseline_time_ms": 0.41891711980104446,
          "optimizations": [
            {
              "file": "optimized_batching_continuous.py",
              "technique": "continuous",
              "status": "success",
              "time_ms": 0.570929279923439,
              "speedup": 0.7337460777230076
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "autotuning",
          "baseline_file": "baseline_autotuning.py",
          "baseline_time_ms": 0.0377920001745224,
          "optimizations": [
            {
              "file": "optimized_autotuning.py",
              "technique": "optimized_autotuning",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: "
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "end",
          "baseline_file": "baseline_end_to_end_bandwidth.py",
          "baseline_time_ms": 0.9937676823139191,
          "optimizations": [
            {
              "file": "optimized_end_to_end_bandwidth.py",
              "technique": "to_end_bandwidth",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: "
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "multiple",
          "baseline_file": "baseline_multiple_unoptimized.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Failed to load baseline"
        },
        {
          "example": "pipeline",
          "baseline_file": "baseline_pipeline_sequential.py",
          "baseline_time_ms": 0.5223577570915222,
          "optimizations": [
            {
              "file": "optimized_pipeline_overlap.py",
              "technique": "overlap",
              "status": "success",
              "time_ms": 0.2882291205227375,
              "speedup": 1.8123004231639217
            }
          ],
          "best_speedup": 1.8123004231639217,
          "status": "success",
          "error": null
        },
        {
          "example": "inference",
          "baseline_file": "baseline_inference_monolithic.py",
          "baseline_time_ms": 17.902694511413575,
          "optimizations": [
            {
              "file": "optimized_inference_disaggregated.py",
              "technique": "disaggregated",
              "status": "success",
              "time_ms": 13.947353601455688,
              "speedup": 1.283590781662341
            }
          ],
          "best_speedup": 1.283590781662341,
          "status": "success",
          "error": null
        },
        {
          "example": "training",
          "baseline_file": "baseline_training_single.py",
          "baseline_time_ms": 0.8368588823080063,
          "optimizations": [
            {
              "file": "optimized_training_distributed.py",
              "technique": "distributed",
              "status": "success",
              "time_ms": 1.9156377577781678,
              "speedup": 0.43685653976596717
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "kv",
          "baseline_file": "baseline_kv_cache_naive.py",
          "baseline_time_ms": 49.611033248901364,
          "optimizations": [
            {
              "file": "optimized_kv_cache_paged.py",
              "technique": "cache_paged",
              "status": "success",
              "time_ms": 127.83658752441406,
              "speedup": 0.38808164555727614
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 14,
        "successful": 11,
        "failed": 3,
        "skipped_hardware": 0,
        "total_speedups": 5,
        "average_speedup": 22.45367475578315,
        "max_speedup": 106.16519148404826,
        "min_speedup": 1.283590781662341
      }
    },
    {
      "chapter": "ch3",
      "status": "completed",
      "benchmarks": [
        {
          "example": "occupancy",
          "baseline_file": "baseline_occupancy.py",
          "baseline_time_ms": 0.5524659162759781,
          "optimizations": [
            {
              "file": "optimized_occupancy.py",
              "technique": "optimized_occupancy",
              "status": "success",
              "time_ms": 0.21764543890953064,
              "speedup": 2.538375805364905
            }
          ],
          "best_speedup": 2.538375805364905,
          "status": "success",
          "error": null
        },
        {
          "example": "streams",
          "baseline_file": "baseline_streams.py",
          "baseline_time_ms": 1.1149429380893707,
          "optimizations": [
            {
              "file": "optimized_streams.py",
              "technique": "optimized_streams",
              "status": "success",
              "time_ms": 0.8422666649023692,
              "speedup": 1.323741024724763
            }
          ],
          "best_speedup": 1.323741024724763,
          "status": "success",
          "error": null
        },
        {
          "example": "cutlass",
          "baseline_file": "baseline_cutlass.py",
          "baseline_time_ms": 0.352607359290123,
          "optimizations": [
            {
              "file": "optimized_cutlass.py",
              "technique": "optimized_cutlass",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: "
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "docker",
          "baseline_file": "baseline_docker.py",
          "baseline_time_ms": 0.21041728049516678,
          "optimizations": [
            {
              "file": "optimized_docker.py",
              "technique": "optimized_docker",
              "status": "success",
              "time_ms": 0.0617945596575737,
              "speedup": 3.405110120715578
            }
          ],
          "best_speedup": 3.405110120715578,
          "status": "success",
          "error": null
        },
        {
          "example": "moe",
          "baseline_file": "baseline_moe.py",
          "baseline_time_ms": 0.21181055963039397,
          "optimizations": [
            {
              "file": "optimized_moe.py",
              "technique": "optimized_moe",
              "status": "success",
              "time_ms": 7.240215001106262,
              "speedup": 0.029254733401981925
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "autotuning",
          "baseline_file": "baseline_autotuning.py",
          "baseline_time_ms": 0.12060736015439033,
          "optimizations": [
            {
              "file": "optimized_autotuning.py",
              "technique": "optimized_autotuning",
              "status": "failed",
              "error": "Failed to load"
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "triton",
          "baseline_file": "baseline_triton.py",
          "baseline_time_ms": 0.059104319997131824,
          "optimizations": [
            {
              "file": "optimized_triton.py",
              "technique": "optimized_triton",
              "status": "success",
              "time_ms": 0.065593600012362,
              "speedup": 0.9010683967032274
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "kubernetes",
          "baseline_file": "baseline_kubernetes.py",
          "baseline_time_ms": 0.12197120003402233,
          "optimizations": [
            {
              "file": "optimized_kubernetes.py",
              "technique": "optimized_kubernetes",
              "status": "success",
              "time_ms": 0.13976256057620048,
              "speedup": 0.8727029580108612
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "hbm",
          "baseline_file": "baseline_hbm.py",
          "baseline_time_ms": 0.06352896004915237,
          "optimizations": [
            {
              "file": "optimized_hbm.py",
              "technique": "optimized_hbm",
              "status": "success",
              "time_ms": 0.2310016006231308,
              "speedup": 0.27501523746061457
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "gemm",
          "baseline_file": "baseline_gemm.py",
          "baseline_time_ms": 0.3437779182195663,
          "optimizations": [
            {
              "file": "optimized_gemm.py",
              "technique": "optimized_gemm",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: "
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "numa",
          "baseline_file": "baseline_numa_unaware.py",
          "baseline_time_ms": 65.8800006866455,
          "optimizations": [
            {
              "file": "optimized_numa_aware.py",
              "technique": "aware",
              "status": "success",
              "time_ms": 67.17394218444824,
              "speedup": 0.9807374488421449
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 11,
        "successful": 8,
        "failed": 3,
        "skipped_hardware": 0,
        "total_speedups": 3,
        "average_speedup": 2.4224089836017484,
        "max_speedup": 3.405110120715578,
        "min_speedup": 1.323741024724763
      }
    },
    {
      "chapter": "ch4",
      "status": "completed",
      "benchmarks": [
        {
          "example": "continuous",
          "baseline_file": "baseline_continuous_batching.py",
          "baseline_time_ms": 0.3260639995336533,
          "optimizations": [
            {
              "file": "optimized_continuous_batching.py",
              "technique": "batching",
              "status": "success",
              "time_ms": 0.006102399993687868,
              "speedup": 53.4320922704057
            }
          ],
          "best_speedup": 53.4320922704057,
          "status": "success",
          "error": null
        },
        {
          "example": "no",
          "baseline_file": "baseline_no_overlap.py",
          "baseline_time_ms": 1.2900048077106476,
          "optimizations": [
            {
              "file": "optimized_no_overlap_overlap.py",
              "technique": "overlap_overlap",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: "
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "dataparallel",
          "baseline_file": "baseline_dataparallel.py",
          "baseline_time_ms": 0.2699888005852699,
          "optimizations": [
            {
              "file": "optimized_dataparallel_ddp.py",
              "technique": "ddp",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: "
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "kv",
          "baseline_file": "baseline_kv_cache_management.py",
          "baseline_time_ms": 2.229148817062378,
          "optimizations": [
            {
              "file": "optimized_kv_cache_management.py",
              "technique": "cache_management",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: expected scalar type Float but found Half\nException raised from check_type at /pytorch/build/aten/src/ATen/core/TensorMethods.cpp:12 (most recent call first):\nframe #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0xb0 (0xeeeb464ac700 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) + 0x68 (0xeeeb4644a860 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libc10.so)\nframe #2: <unknown function> + 0x2d3568c (0xeeeb6484568c in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #3: float const* at::TensorBase::const_data_ptr<float, 0>() const + 0x24 (0xeeeb64846324 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #4: <unknown function> + 0xa66f6c (0xeeeb46c86f6c in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\nframe #5: at::native::structured_bmm_out_cuda::impl(at::Tensor const&, at::Tensor const&, at::Tensor const&) + 0x64 (0xeeeb46c87bb4 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\nframe #6: <unknown function> + 0xa5bfac (0xeeeb46c7bfac in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\nframe #7: <unknown function> + 0xa5c02c (0xeeeb46c7c02c in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cuda.so)\nframe #8: at::_ops::bmm::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&) + 0x80 (0xeeeb62d6c3d0 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #9: <unknown function> + 0x1277bfc (0xeeeb62d87bfc in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #10: <unknown function> + 0x12781e0 (0xeeeb62d881e0 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #11: at::_ops::bmm::call(at::Tensor const&, at::Tensor const&) + 0xb8 (0xeeeb62d6e038 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #12: <unknown function> + 0x1233a3c (0xeeeb62d43a3c in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #13: at::native::matmul(at::Tensor const&, at::Tensor const&) + 0x5c (0xeeeb62d4421c in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #14: <unknown function> + 0x1268ffc (0xeeeb62d78ffc in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #15: at::_ops::matmul::call(at::Tensor const&, at::Tensor const&) + 0xb8 (0xeeeb62d738f8 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_cpu.so)\nframe #16: <unknown function> + 0x5e5a94 (0xeeeb6c0f5a94 in /home/cfregly/.local/lib/python3.11/site-packages/torch/lib/libtorch_python.so)\nframe #17: python() [0x4d9630]\n<omitting python frames>\nframe #20: python() [0x514354]\nframe #22: python() [0x514354]\nframe #27: python() [0x616798]\nframe #32: python() [0x514c68]\nframe #33: python() [0x514548]\nframe #34: python() [0x64013c]\nframe #35: python() [0x5f6de4]\nframe #36: <unknown function> + 0x8595c (0xeeeb7ae3595c in /lib/aarch64-linux-gnu/libc.so.6)\nframe #37: <unknown function> + 0xebb0c (0xeeeb7ae9bb0c in /lib/aarch64-linux-gnu/libc.so.6)\n"
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "disaggregated",
          "baseline_file": "baseline_disaggregated.py",
          "baseline_time_ms": 0.3531295984983444,
          "optimizations": [
            {
              "file": "optimized_disaggregated.py",
              "technique": "optimized_disaggregated",
              "status": "success",
              "time_ms": 0.05859199985861778,
              "speedup": 6.026925166412556
            }
          ],
          "best_speedup": 6.026925166412556,
          "status": "success",
          "error": null
        },
        {
          "example": "reinit",
          "baseline_file": "baseline_reinit_comm.py",
          "baseline_time_ms": 524.7219604492187,
          "optimizations": [
            {
              "file": "optimized_reinit_comm.py",
              "technique": "comm",
              "status": "success",
              "time_ms": 0.02404480017721653,
              "speedup": 21822.67918975742
            }
          ],
          "best_speedup": 21822.67918975742,
          "status": "success",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 6,
        "successful": 3,
        "failed": 3,
        "skipped_hardware": 0,
        "total_speedups": 3,
        "average_speedup": 7294.046069064745,
        "max_speedup": 21822.67918975742,
        "min_speedup": 6.026925166412556
      }
    },
    {
      "chapter": "ch5",
      "status": "completed",
      "benchmarks": [
        {
          "example": "nvlink",
          "baseline_file": "baseline_nvlink.py",
          "baseline_time_ms": 3.9444960069656374,
          "optimizations": [
            {
              "file": "optimized_nvlink.py",
              "technique": "optimized_nvlink",
              "status": "success",
              "time_ms": 1.7785075163841249,
              "speedup": 2.217868617718959
            }
          ],
          "best_speedup": 2.217868617718959,
          "status": "success",
          "error": null
        },
        {
          "example": "ai",
          "baseline_file": "baseline_ai_optimization.py",
          "baseline_time_ms": 0.011270400043576956,
          "optimizations": [
            {
              "file": "optimized_ai_optimization.py",
              "technique": "optimization",
              "status": "success",
              "time_ms": 0.06818048045039177,
              "speedup": 0.16530244388314802
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "distributed",
          "baseline_file": "baseline_distributed.py",
          "baseline_time_ms": 0.1469612804055214,
          "optimizations": [
            {
              "file": "optimized_distributed.py",
              "technique": "optimized_distributed",
              "status": "success",
              "time_ms": 0.1683283206820488,
              "speedup": 0.8730633075292952
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "roofline",
          "baseline_file": "baseline_roofline.py",
          "baseline_time_ms": 0.19754112005233765,
          "optimizations": [
            {
              "file": "optimized_roofline.py",
              "technique": "optimized_roofline",
              "status": "success",
              "time_ms": 0.6314374369382858,
              "speedup": 0.31284353523632547
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "storage",
          "baseline_file": "baseline_storage_cpu.py",
          "baseline_time_ms": 78.11426315307617,
          "optimizations": [
            {
              "file": "optimized_storage_gds.py",
              "technique": "gds",
              "status": "success",
              "time_ms": 66.99818325042725,
              "speedup": 1.1659161392645379
            }
          ],
          "best_speedup": 1.1659161392645379,
          "status": "success",
          "error": null
        },
        {
          "example": "vectorization",
          "baseline_file": "baseline_vectorization.py",
          "baseline_time_ms": 3.721155195236206,
          "optimizations": [
            {
              "file": "optimized_vectorization.py",
              "technique": "optimized_vectorization",
              "status": "success",
              "time_ms": 0.012429440021514892,
              "speedup": 299.38236869843104
            }
          ],
          "best_speedup": 299.38236869843104,
          "status": "success",
          "error": null
        },
        {
          "example": "nccl",
          "baseline_file": "baseline_nccl.py",
          "baseline_time_ms": 0.8062559995055198,
          "optimizations": [
            {
              "file": "optimized_nccl.py",
              "technique": "optimized_nccl",
              "status": "success",
              "time_ms": 0.20994175970554352,
              "speedup": 3.8403793539519935
            }
          ],
          "best_speedup": 3.8403793539519935,
          "status": "success",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 7,
        "successful": 7,
        "failed": 0,
        "skipped_hardware": 0,
        "total_speedups": 4,
        "average_speedup": 76.65163320234164,
        "max_speedup": 299.38236869843104,
        "min_speedup": 1.1659161392645379
      }
    },
    {
      "chapter": "ch6",
      "status": "completed",
      "benchmarks": [
        {
          "example": "attention",
          "baseline_file": "baseline_attention_ilp.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Failed to load baseline"
        },
        {
          "example": "ai",
          "baseline_file": "baseline_ai_optimization.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Failed to load baseline"
        },
        {
          "example": "warp",
          "baseline_file": "baseline_warp_divergence_ilp.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Failed to load baseline"
        },
        {
          "example": "quantization",
          "baseline_file": "baseline_quantization_ilp.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Failed to load baseline"
        },
        {
          "example": "distributed",
          "baseline_file": "baseline_distributed_ilp.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Failed to load baseline"
        },
        {
          "example": "adaptive",
          "baseline_file": "baseline_adaptive.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Failed to load baseline"
        },
        {
          "example": "autotuning",
          "baseline_file": "baseline_autotuning.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Failed to load baseline"
        },
        {
          "example": "ilp",
          "baseline_file": "baseline_ilp.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: TIMEOUT: Benchmark exceeded timeout of 15 seconds"
        },
        {
          "example": "coalescing",
          "baseline_file": "baseline_coalescing.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: TIMEOUT: Benchmark exceeded timeout of 15 seconds"
        },
        {
          "example": "triton",
          "baseline_file": "baseline_triton.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Failed to load baseline"
        },
        {
          "example": "launch",
          "baseline_file": "baseline_launch_bounds.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: TIMEOUT: Benchmark exceeded timeout of 15 seconds"
        },
        {
          "example": "add",
          "baseline_file": "baseline_add.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Failed to load baseline"
        },
        {
          "example": "gemm",
          "baseline_file": "baseline_gemm_ilp.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Failed to load baseline"
        },
        {
          "example": "bank",
          "baseline_file": "baseline_bank_conflicts.py",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed: Benchmark failed: TIMEOUT: Benchmark exceeded timeout of 15 seconds"
        },
        {
          "example": "coalescing",
          "baseline_file": "baseline_coalescing_uncoalesced.cu",
          "type": "cuda",
          "baseline_time_ms": 504.08112194988917,
          "optimizations": [
            {
              "file": "optimized_coalescing.cu",
              "technique": "optimized_coalescing",
              "status": "success",
              "time_ms": 362.95942340004785,
              "speedup": 1.3888084712827509
            }
          ],
          "best_speedup": 1.3888084712827509,
          "status": "success",
          "error": null
        },
        {
          "example": "launch",
          "baseline_file": "baseline_launch_bounds.cu",
          "type": "cuda",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline executable not found for baseline_launch_bounds.cu"
        },
        {
          "example": "add",
          "baseline_file": "baseline_add.cu",
          "type": "cuda",
          "baseline_time_ms": 296.6428019000432,
          "optimizations": [
            {
              "file": "optimized_add_parallel.cu",
              "technique": "parallel",
              "status": "success",
              "time_ms": 200.64542200002506,
              "speedup": 1.4784429115955915
            }
          ],
          "best_speedup": 1.4784429115955915,
          "status": "success",
          "error": null
        },
        {
          "example": "ilp",
          "baseline_file": "baseline_ilp.cu",
          "type": "cuda",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed or timed out"
        },
        {
          "example": "bank",
          "baseline_file": "baseline_bank_conflicts.cu",
          "type": "cuda",
          "baseline_time_ms": null,
          "optimizations": [],
          "best_speedup": 1.0,
          "status": "failed",
          "error": "Baseline execution failed or timed out"
        }
      ],
      "summary": {
        "total_benchmarks": 19,
        "successful": 2,
        "failed": 17,
        "skipped_hardware": 0,
        "total_speedups": 2,
        "average_speedup": 1.4336256914391712,
        "max_speedup": 1.4784429115955915,
        "min_speedup": 1.3888084712827509
      }
    },
    {
      "chapter": "ch7",
      "status": "completed",
      "benchmarks": [
        {
          "example": "loop",
          "baseline_file": "baseline_loop_unrolling.py",
          "baseline_time_ms": 343.95188395182294,
          "optimizations": [
            {
              "file": "optimized_loop_unrolling.py",
              "technique": "unrolling",
              "status": "success",
              "time_ms": 329.1078796386719,
              "speedup": 1.0451037645450736
            }
          ],
          "best_speedup": 1.0451037645450736,
          "status": "success",
          "error": null
        },
        {
          "example": "occupancy",
          "baseline_file": "baseline_occupancy.py",
          "baseline_time_ms": 0.08440319940447807,
          "optimizations": [
            {
              "file": "optimized_occupancy.py",
              "technique": "optimized_occupancy",
              "status": "success",
              "time_ms": 0.19280895829200745,
              "speedup": 0.4377555905709017
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "nvlink",
          "baseline_file": "baseline_nvlink.py",
          "baseline_time_ms": 140.09860790252685,
          "optimizations": [
            {
              "file": "optimized_nvlink.py",
              "technique": "optimized_nvlink",
              "status": "success",
              "time_ms": 4.5782605028152465,
              "speedup": 30.600837985601288
            }
          ],
          "best_speedup": 30.600837985601288,
          "status": "success",
          "error": null
        },
        {
          "example": "double",
          "baseline_file": "baseline_double_buffering.py",
          "baseline_time_ms": 2.561292791366577,
          "optimizations": [
            {
              "file": "optimized_double_buffering.py",
              "technique": "buffering",
              "status": "success",
              "time_ms": 24.38684787750244,
              "speedup": 0.1050276281802472
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "lookup",
          "baseline_file": "baseline_lookup.py",
          "baseline_time_ms": 213.68126932779947,
          "optimizations": [
            {
              "file": "optimized_lookup.py",
              "technique": "optimized_lookup",
              "status": "success",
              "time_ms": 196.5343271891276,
              "speedup": 1.0872465506861362
            }
          ],
          "best_speedup": 1.0872465506861362,
          "status": "success",
          "error": null
        },
        {
          "example": "cutlass",
          "baseline_file": "baseline_cutlass.py",
          "baseline_time_ms": 0.36291839957237243,
          "optimizations": [
            {
              "file": "optimized_cutlass.py",
              "technique": "optimized_cutlass",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: "
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "scalar",
          "baseline_file": "baseline_scalar_copy.py",
          "baseline_time_ms": 203.75796508789062,
          "optimizations": [
            {
              "file": "optimized_scalar_copy.py",
              "technique": "copy",
              "status": "success",
              "time_ms": 208.93338521321616,
              "speedup": 0.9752293290991096
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "hbm3epeak",
          "baseline_file": "baseline_hbm3epeak.py",
          "baseline_time_ms": 288.18443806966144,
          "optimizations": [
            {
              "file": "optimized_hbm3epeak.py",
              "technique": "optimized_hbm3epeak",
              "status": "success",
              "time_ms": 318.323486328125,
              "speedup": 0.9053194327376884
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "memory",
          "baseline_file": "baseline_memory_access.py",
          "baseline_time_ms": 0.2916454410552978,
          "optimizations": [
            {
              "file": "optimized_memory_access.py",
              "technique": "access",
              "status": "success",
              "time_ms": 0.4322464007139206,
              "speedup": 0.67472034601931
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "async",
          "baseline_file": "baseline_async_prefetch.py",
          "baseline_time_ms": 192.78494771321616,
          "optimizations": [
            {
              "file": "optimized_async_prefetch.py",
              "technique": "prefetch",
              "status": "success",
              "time_ms": 1.5483733415603638,
              "speedup": 124.50805147480665
            }
          ],
          "best_speedup": 124.50805147480665,
          "status": "success",
          "error": null
        },
        {
          "example": "hbm3ecopy",
          "baseline_file": "baseline_hbm3ecopy.py",
          "baseline_time_ms": 486.9869689941406,
          "optimizations": [
            {
              "file": "optimized_hbm3ecopy.py",
              "technique": "optimized_hbm3ecopy",
              "status": "success",
              "time_ms": 1157.9773356119792,
              "speedup": 0.4205496550040619
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "autotuning",
          "baseline_file": "baseline_autotuning.py",
          "baseline_time_ms": 0.128611840903759,
          "optimizations": [
            {
              "file": "optimized_autotuning.py",
              "technique": "optimized_autotuning",
              "status": "success",
              "time_ms": 0.14266624048352242,
              "speedup": 0.9014875591301036
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "roofline",
          "baseline_file": "baseline_roofline.py",
          "baseline_time_ms": 0.07587584003806114,
          "optimizations": [
            {
              "file": "optimized_roofline.py",
              "technique": "optimized_roofline",
              "status": "success",
              "time_ms": 0.1830726397782564,
              "speedup": 0.4144575624733682
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "warp",
          "baseline_file": "baseline_warp_divergence.py",
          "baseline_time_ms": 0.11890175968408584,
          "optimizations": [
            {
              "file": "optimized_warp_divergence.py",
              "technique": "divergence",
              "status": "success",
              "time_ms": 0.048956159371882677,
              "speedup": 2.4287395336893094
            }
          ],
          "best_speedup": 2.4287395336893094,
          "status": "success",
          "error": null
        },
        {
          "example": "transpose",
          "baseline_file": "baseline_transpose.py",
          "baseline_time_ms": 197.0868174235026,
          "optimizations": [
            {
              "file": "optimized_transpose_padded.py",
              "technique": "padded",
              "status": "success",
              "time_ms": 196.2667439778646,
              "speedup": 1.0041783616980495
            }
          ],
          "best_speedup": 1.0041783616980495,
          "status": "success",
          "error": null
        },
        {
          "example": "triton",
          "baseline_file": "baseline_triton.py",
          "baseline_time_ms": 0.21638272002339362,
          "optimizations": [
            {
              "file": "optimized_triton.py",
              "technique": "optimized_triton",
              "status": "success",
              "time_ms": 0.07736191995441914,
              "speedup": 2.7970184833944676
            }
          ],
          "best_speedup": 2.7970184833944676,
          "status": "success",
          "error": null
        },
        {
          "example": "matmul",
          "baseline_file": "baseline_matmul.py",
          "baseline_time_ms": 187.57662963867188,
          "optimizations": [
            {
              "file": "optimized_matmul_tiled.py",
              "technique": "tiled",
              "status": "success",
              "time_ms": 175.1847381591797,
              "speedup": 1.07073613609099
            }
          ],
          "best_speedup": 1.07073613609099,
          "status": "success",
          "error": null
        },
        {
          "example": "tma",
          "baseline_file": "baseline_tma_copy.py",
          "baseline_time_ms": 184.65433756510416,
          "optimizations": [
            {
              "file": "optimized_tma_copy.py",
              "technique": "copy",
              "status": "success",
              "time_ms": 187.20191955566406,
              "speedup": 0.9863912613898044
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "uncoalesced",
          "baseline_file": "baseline_uncoalesced_copy.py",
          "baseline_time_ms": 193.60964965820312,
          "optimizations": [
            {
              "file": "optimized_uncoalesced_copy.py",
              "technique": "copy",
              "status": "success",
              "time_ms": 196.6709238688151,
              "speedup": 0.984434535871434
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "loop",
          "baseline_file": "baseline_loop_unrolling.cu",
          "type": "cuda",
          "baseline_time_ms": 199.38214854998932,
          "optimizations": [
            {
              "file": "optimized_loop_unrolling.cu",
              "technique": "unrolling",
              "status": "success",
              "time_ms": 198.3442587000127,
              "speedup": 1.0052327698153662
            }
          ],
          "best_speedup": 1.0052327698153662,
          "status": "success",
          "error": null
        },
        {
          "example": "hbm3e",
          "baseline_file": "baseline_hbm3e_copy.cu",
          "type": "cuda",
          "baseline_time_ms": 441.6986086999941,
          "optimizations": [
            {
              "file": "optimized_hbm3e_peak.cu",
              "technique": "peak",
              "status": "success",
              "time_ms": 292.34281844996985,
              "speedup": 1.510892626136408
            },
            {
              "file": "optimized_hbm3e_copy.cu",
              "technique": "copy",
              "status": "success",
              "time_ms": 1137.0680698500337,
              "speedup": 0.38845397246819985
            }
          ],
          "best_speedup": 1.510892626136408,
          "status": "success",
          "error": null
        },
        {
          "example": "async",
          "baseline_file": "baseline_async_prefetch.cu",
          "type": "cuda",
          "baseline_time_ms": 151.8071659500265,
          "optimizations": [
            {
              "file": "optimized_async_prefetch.cu",
              "technique": "prefetch",
              "status": "success",
              "time_ms": 1.6547994000120525,
              "speedup": 91.73750362063271
            }
          ],
          "best_speedup": 91.73750362063271,
          "status": "success",
          "error": null
        },
        {
          "example": "matmul",
          "baseline_file": "baseline_matmul.cu",
          "type": "cuda",
          "baseline_time_ms": 150.49126189994695,
          "optimizations": [
            {
              "file": "optimized_matmul_tiled.cu",
              "technique": "tiled",
              "status": "success",
              "time_ms": 164.0286414000002,
              "speedup": 0.9174694164109974
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "transpose",
          "baseline_file": "baseline_transpose.cu",
          "type": "cuda",
          "baseline_time_ms": 199.8381512999913,
          "optimizations": [
            {
              "file": "optimized_transpose_padded.cu",
              "technique": "padded",
              "status": "success",
              "time_ms": 187.53875559998505,
              "speedup": 1.0655832212422296
            }
          ],
          "best_speedup": 1.0655832212422296,
          "status": "success",
          "error": null
        },
        {
          "example": "hbm3e",
          "baseline_file": "baseline_hbm3e_peak.cu",
          "type": "cuda",
          "baseline_time_ms": 292.5822693999862,
          "optimizations": [
            {
              "file": "optimized_hbm3e_peak.cu",
              "technique": "peak",
              "status": "success",
              "time_ms": 307.32490180000696,
              "speedup": 0.952029164204811
            },
            {
              "file": "optimized_hbm3e_copy.cu",
              "technique": "copy",
              "status": "success",
              "time_ms": 1200.6833347499196,
              "speedup": 0.24367979543992402
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "tma",
          "baseline_file": "baseline_tma_copy.cu",
          "type": "cuda",
          "baseline_time_ms": 148.73007980002058,
          "optimizations": [
            {
              "file": "optimized_tma_copy.cu",
              "technique": "copy",
              "status": "success",
              "time_ms": 150.4682893500103,
              "speedup": 0.9884480008545428
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "copy",
          "baseline_file": "baseline_copy_uncoalesced.cu",
          "type": "cuda",
          "baseline_time_ms": 154.32266740001523,
          "optimizations": [
            {
              "file": "optimized_copy_coalesced.cu",
              "technique": "coalesced",
              "status": "success",
              "time_ms": 153.2253948500511,
              "speedup": 1.0071611664048115
            },
            {
              "file": "optimized_copy_vectorized.cu",
              "technique": "vectorized",
              "status": "success",
              "time_ms": 157.9162196499965,
              "speedup": 0.9772439318903026
            }
          ],
          "best_speedup": 1.0071611664048115,
          "status": "success",
          "error": null
        },
        {
          "example": "lookup",
          "baseline_file": "baseline_lookup.cu",
          "type": "cuda",
          "baseline_time_ms": 156.1866503000374,
          "optimizations": [
            {
              "file": "optimized_lookup.cu",
              "technique": "optimized_lookup",
              "status": "success",
              "time_ms": 154.96656995001103,
              "speedup": 1.0078731841997919
            }
          ],
          "best_speedup": 1.0078731841997919,
          "status": "success",
          "error": null
        },
        {
          "example": "copy",
          "baseline_file": "baseline_copy_scalar.cu",
          "type": "cuda",
          "baseline_time_ms": 151.49321954995685,
          "optimizations": [
            {
              "file": "optimized_copy_coalesced.cu",
              "technique": "coalesced",
              "status": "success",
              "time_ms": 151.91410774993983,
              "speedup": 0.9972294330907319
            },
            {
              "file": "optimized_copy_vectorized.cu",
              "technique": "vectorized",
              "status": "success",
              "time_ms": 155.55103354997755,
              "speedup": 0.973913294515546
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 29,
        "successful": 28,
        "failed": 1,
        "skipped_hardware": 0,
        "total_speedups": 14,
        "average_speedup": 18.70543991992452,
        "max_speedup": 124.50805147480665,
        "min_speedup": 1.0041783616980495
      }
    },
    {
      "chapter": "ch8",
      "status": "completed",
      "benchmarks": [
        {
          "example": "loop",
          "baseline_file": "baseline_loop_unrolling.py",
          "baseline_time_ms": 146.8481201171875,
          "optimizations": [
            {
              "file": "optimized_loop_unrolling.py",
              "technique": "unrolling",
              "status": "success",
              "time_ms": 154.38888549804688,
              "speedup": 0.9511573300336132
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "occupancy",
          "baseline_file": "baseline_occupancy.py",
          "baseline_time_ms": 8.542844820022584,
          "optimizations": [
            {
              "file": "optimized_occupancy.py",
              "technique": "optimized_occupancy",
              "status": "success",
              "time_ms": 0.05026815995573997,
              "speedup": 169.94544513951521
            }
          ],
          "best_speedup": 169.94544513951521,
          "status": "success",
          "error": null
        },
        {
          "example": "nvlink",
          "baseline_file": "baseline_nvlink.py",
          "baseline_time_ms": 120.34168659210205,
          "optimizations": [
            {
              "file": "optimized_nvlink.py",
              "technique": "optimized_nvlink",
              "status": "success",
              "time_ms": 2.31084032535553,
              "speedup": 52.077023787261076
            }
          ],
          "best_speedup": 52.077023787261076,
          "status": "success",
          "error": null
        },
        {
          "example": "double",
          "baseline_file": "baseline_double_buffering.py",
          "baseline_time_ms": 4.869971191883087,
          "optimizations": [
            {
              "file": "optimized_double_buffering.py",
              "technique": "buffering",
              "status": "success",
              "time_ms": 0.7800319969654084,
              "speedup": 6.243296699146884
            }
          ],
          "best_speedup": 6.243296699146884,
          "status": "success",
          "error": null
        },
        {
          "example": "ai",
          "baseline_file": "baseline_ai_optimization.py",
          "baseline_time_ms": 0.11572736009955406,
          "optimizations": [
            {
              "file": "optimized_ai_optimization.py",
              "technique": "optimization",
              "status": "success",
              "time_ms": 0.8785849595069886,
              "speedup": 0.13172016985641732
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "distributed",
          "baseline_file": "baseline_distributed.py",
          "baseline_time_ms": 0.22611648052930833,
          "optimizations": [
            {
              "file": "optimized_distributed.py",
              "technique": "optimized_distributed",
              "status": "success",
              "time_ms": 0.1583993598818779,
              "speedup": 1.4275088024214786
            }
          ],
          "best_speedup": 1.4275088024214786,
          "status": "success",
          "error": null
        },
        {
          "example": "quantization",
          "baseline_file": "baseline_quantization.py",
          "baseline_time_ms": 0.24976959988474845,
          "optimizations": [
            {
              "file": "optimized_quantization.py",
              "technique": "optimized_quantization",
              "status": "success",
              "time_ms": 0.20850495964288712,
              "speedup": 1.1979072359359535
            }
          ],
          "best_speedup": 1.1979072359359535,
          "status": "success",
          "error": null
        },
        {
          "example": "roofline",
          "baseline_file": "baseline_roofline.py",
          "baseline_time_ms": 0.06818048030138016,
          "optimizations": [
            {
              "file": "optimized_roofline.py",
              "technique": "optimized_roofline",
              "status": "success",
              "time_ms": 0.26408511996269224,
              "speedup": 0.25817615286697004
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "coalescing",
          "baseline_file": "baseline_coalescing.py",
          "baseline_time_ms": 0.1579212812334299,
          "optimizations": [
            {
              "file": "optimized_coalescing.py",
              "technique": "optimized_coalescing",
              "status": "success",
              "time_ms": 0.042169600017368795,
              "speedup": 3.7449082080073173
            }
          ],
          "best_speedup": 3.7449082080073173,
          "status": "success",
          "error": null
        },
        {
          "example": "threshold",
          "baseline_file": "baseline_threshold.py",
          "baseline_time_ms": 1386.5113037109375,
          "optimizations": [
            {
              "file": "optimized_threshold_predicated.py",
              "technique": "predicated",
              "status": "success",
              "time_ms": 2014.9698486328125,
              "speedup": 0.6881052362404858
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "tiling",
          "baseline_file": "baseline_tiling.py",
          "baseline_time_ms": 0.2929695987701416,
          "optimizations": [
            {
              "file": "optimized_tiling.py",
              "technique": "optimized_tiling",
              "status": "success",
              "time_ms": 0.5317964798212051,
              "speedup": 0.5509054871304163
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "nccl",
          "baseline_file": "baseline_nccl.py",
          "baseline_time_ms": 0.6457184022665023,
          "optimizations": [
            {
              "file": "optimized_nccl.py",
              "technique": "optimized_nccl",
              "status": "success",
              "time_ms": 0.19117503970861435,
              "speedup": 3.3776292305245237
            }
          ],
          "best_speedup": 3.3776292305245237,
          "status": "success",
          "error": null
        },
        {
          "example": "hbm",
          "baseline_file": "baseline_hbm.py",
          "baseline_time_ms": 0.19211584001779555,
          "optimizations": [
            {
              "file": "optimized_hbm.py",
              "technique": "optimized_hbm",
              "status": "success",
              "time_ms": 0.23035135954618455,
              "speedup": 0.834012182069527
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "loop",
          "baseline_file": "baseline_loop_unrolling.cu",
          "type": "cuda",
          "baseline_time_ms": 198.96618935001698,
          "optimizations": [
            {
              "file": "optimized_loop_unrolling.cu",
              "technique": "unrolling",
              "status": "success",
              "time_ms": 185.49766194996664,
              "speedup": 1.0726075318603376
            }
          ],
          "best_speedup": 1.0726075318603376,
          "status": "success",
          "error": null
        },
        {
          "example": "threshold",
          "baseline_file": "baseline_threshold.cu",
          "type": "cuda",
          "baseline_time_ms": 1390.9292892500162,
          "optimizations": [
            {
              "file": "optimized_threshold_predicated.cu",
              "technique": "predicated",
              "status": "success",
              "time_ms": 1976.5214481500607,
              "speedup": 0.7037258768691158
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 15,
        "successful": 15,
        "failed": 0,
        "skipped_hardware": 0,
        "total_speedups": 8,
        "average_speedup": 29.885790829334102,
        "max_speedup": 169.94544513951521,
        "min_speedup": 1.0726075318603376
      }
    },
    {
      "chapter": "ch9",
      "status": "completed",
      "benchmarks": [
        {
          "example": "nvlink",
          "baseline_file": "baseline_nvlink.py",
          "baseline_time_ms": 107.63715915679931,
          "optimizations": [
            {
              "file": "optimized_nvlink.py",
              "technique": "optimized_nvlink",
              "status": "success",
              "time_ms": 2.359865584373474,
              "speedup": 45.61156358631169
            }
          ],
          "best_speedup": 45.61156358631169,
          "status": "success",
          "error": null
        },
        {
          "example": "double",
          "baseline_file": "baseline_double_buffering.py",
          "baseline_time_ms": 3.6236927986145018,
          "optimizations": [
            {
              "file": "optimized_double_buffering.py",
              "technique": "buffering",
              "status": "success",
              "time_ms": 1.0063456118106842,
              "speedup": 3.6008432451894055
            }
          ],
          "best_speedup": 3.6008432451894055,
          "status": "success",
          "error": null
        },
        {
          "example": "flash",
          "baseline_file": "baseline_flash_attention.py",
          "baseline_time_ms": 0.22456256046891213,
          "optimizations": [
            {
              "file": "optimized_flash_attention.py",
              "technique": "attention",
              "status": "success",
              "time_ms": 0.06926656022667885,
              "speedup": 3.24200537364665
            }
          ],
          "best_speedup": 3.24200537364665,
          "status": "success",
          "error": null
        },
        {
          "example": "memory",
          "baseline_file": "baseline_memory_bound.py",
          "baseline_time_ms": 0.40269887924194336,
          "optimizations": [
            {
              "file": "optimized_memory_bound.py",
              "technique": "bound",
              "status": "success",
              "time_ms": 4.385489912033081,
              "speedup": 0.09182528915116239
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "distributed",
          "baseline_file": "baseline_distributed.py",
          "baseline_time_ms": 0.13705663971602916,
          "optimizations": [
            {
              "file": "optimized_distributed.py",
              "technique": "optimized_distributed",
              "status": "success",
              "time_ms": 0.09738176055252552,
              "speedup": 1.4074159158593555
            }
          ],
          "best_speedup": 1.4074159158593555,
          "status": "success",
          "error": null
        },
        {
          "example": "quantization",
          "baseline_file": "baseline_quantization.py",
          "baseline_time_ms": 0.048326399847865104,
          "optimizations": [
            {
              "file": "optimized_quantization.py",
              "technique": "optimized_quantization",
              "status": "success",
              "time_ms": 0.14187391966581345,
              "speedup": 0.34062920064306956
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "moe",
          "baseline_file": "baseline_moe.py",
          "baseline_time_ms": 0.11563200071454048,
          "optimizations": [
            {
              "file": "optimized_moe.py",
              "technique": "optimized_moe",
              "status": "success",
              "time_ms": 7.105919332504272,
              "speedup": 0.016272630648311817
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "autotuning",
          "baseline_file": "baseline_autotuning.py",
          "baseline_time_ms": 0.1253587194532156,
          "optimizations": [
            {
              "file": "optimized_autotuning.py",
              "technique": "optimized_autotuning",
              "status": "failed",
              "error": "Benchmark failed: Benchmark execution failed: CppCompileError: C++ compile error\n\nCommand:\ng++ .torch_inductor/od/coddh4nx4vbgj2awaasgvxa4cofwce2okot4zjwr637ec7ttlijw.main.cpp -D TORCH_INDUCTOR_CPP_WRAPPER -D STANDALONE_TORCH_HEADER -D C10_USING_CUSTOM_GENERATED_MACROS -D CPU_CAPABILITY_NEON -D AT_BUILD_ARM_VEC256_WITH_SLEEF -O3 -DNDEBUG -fno-trapping-math -funsafe-math-optimizations -ffinite-math-only -fno-signed-zeros -fno-math-errno -fno-finite-math-only -fno-unsafe-math-optimizations -ffp-contract=off -fexcess-precision=fast -fno-tree-loop-vectorize -march=native -shared -fPIC -Wall -std=c++17 -Wno-unused-variable -Wno-unknown-pragmas -pedantic -fopenmp -I/usr/include/python3.11 -I/home/cfregly/.local/lib/python3.11/site-packages/torch/include -I/home/cfregly/.local/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -o .torch_inductor/od/coddh4nx4vbgj2awaasgvxa4cofwce2okot4zjwr637ec7ttlijw.main.so -ltorch -ltorch_cpu -ltorch_python -lgomp -lc10 -L/usr/lib/aarch64-linux-gnu -L/home/cfregly/.local/lib/python3.11/site-packages/torch/lib\n\nOutput:\ncc1plus: fatal error: .torch_inductor/od/coddh4nx4vbgj2awaasgvxa4cofwce2okot4zjwr637ec7ttlijw.main.cpp: No such file or directory\ncompilation terminated.\n\n"
            }
          ],
          "best_speedup": 1.0,
          "status": "failed",
          "error": null
        },
        {
          "example": "cutlass",
          "baseline_file": "baseline_cutlass_gemm.py",
          "baseline_time_ms": 127.83494313557942,
          "optimizations": [
            {
              "file": "optimized_cutlass_gemm.py",
              "technique": "gemm",
              "status": "success",
              "time_ms": 128.74297332763672,
              "speedup": 0.9929469533863688
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "warp",
          "baseline_file": "baseline_warp_specialization.py",
          "baseline_time_ms": 0.2242028796672821,
          "optimizations": [
            {
              "file": "optimized_warp_specialization.py",
              "technique": "specialization",
              "status": "success",
              "time_ms": 0.12088768020272254,
              "speedup": 1.8546379522818635
            }
          ],
          "best_speedup": 1.8546379522818635,
          "status": "success",
          "error": null
        },
        {
          "example": "micro",
          "baseline_file": "baseline_micro_tiling_matmul.py",
          "baseline_time_ms": 255.92505900065103,
          "optimizations": [
            {
              "file": "optimized_micro_tiling_matmul.py",
              "technique": "tiling_matmul",
              "status": "success",
              "time_ms": 183.13041178385416,
              "speedup": 1.3975016847704969
            }
          ],
          "best_speedup": 1.3975016847704969,
          "status": "success",
          "error": null
        },
        {
          "example": "compute",
          "baseline_file": "baseline_compute_bound.py",
          "baseline_time_ms": 4.394689960479736,
          "optimizations": [
            {
              "file": "optimized_compute_bound.py",
              "technique": "bound",
              "status": "success",
              "time_ms": 4.405050868988037,
              "speedup": 0.9976479480449947
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "triton",
          "baseline_file": "baseline_triton.py",
          "baseline_time_ms": 0.07591776009649039,
          "optimizations": [
            {
              "file": "optimized_triton.py",
              "technique": "optimized_triton",
              "status": "success",
              "time_ms": 0.042552000060677525,
              "speedup": 1.7841173150083325
            }
          ],
          "best_speedup": 1.7841173150083325,
          "status": "success",
          "error": null
        },
        {
          "example": "hbm",
          "baseline_file": "baseline_hbm.py",
          "baseline_time_ms": 0.13516543969511985,
          "optimizations": [
            {
              "file": "optimized_hbm.py",
              "technique": "optimized_hbm",
              "status": "success",
              "time_ms": 0.22103167831897735,
              "speedup": 0.6115206685444364
            }
          ],
          "best_speedup": 1.0,
          "status": "success",
          "error": null
        },
        {
          "example": "fused",
          "baseline_file": "baseline_fused_l2norm.py",
          "baseline_time_ms": 169.39462890625,
          "optimizations": [
            {
              "file": "optimized_fused_l2norm.py",
              "technique": "l2norm",
              "status": "success",
              "time_ms": 142.9951385498047,
              "speedup": 1.1846180969799227
            }
          ],
          "best_speedup": 1.1846180969799227,
          "status": "success",
          "error": null
        },
        {
          "example": "bank",
          "baseline_file": "baseline_bank_conflicts.py",
          "baseline_time_ms": 0.13560640066862106,
          "optimizations": [
            {
              "file": "optimized_bank_conflicts.py",
              "technique": "conflicts",
              "status": "success",
              "time_ms": 0.051035520434379575,
              "speedup": 2.657098419187887
            }
          ],
          "best_speedup": 2.657098419187887,
          "status": "success",
          "error": null
        },
        {
          "example": "micro",
          "baseline_file": "baseline_micro_tiling_matmul.cu",
          "type": "cuda",
          "baseline_time_ms": 258.7440430999777,
          "optimizations": [
            {
              "file": "optimized_micro_tiling_matmul.cu",
              "technique": "tiling_matmul",
              "status": "success",
              "time_ms": 186.58243805004986,
              "speedup": 1.3867545402669186
            }
          ],
          "best_speedup": 1.3867545402669186,
          "status": "success",
          "error": null
        },
        {
          "example": "fused",
          "baseline_file": "baseline_fused_l2norm.cu",
          "type": "cuda",
          "baseline_time_ms": 181.01519044998895,
          "optimizations": [
            {
              "file": "optimized_fused_l2norm.cu",
              "technique": "l2norm",
              "status": "success",
              "time_ms": 147.12876774997312,
              "speedup": 1.2303181302897985
            }
          ],
          "best_speedup": 1.2303181302897985,
          "status": "success",
          "error": null
        },
        {
          "example": "cutlass",
          "baseline_file": "baseline_cutlass_gemm.cu",
          "type": "cuda",
          "baseline_time_ms": 140.46957110008407,
          "optimizations": [
            {
              "file": "optimized_cutlass_gemm.cu",
              "technique": "gemm",
              "status": "success",
              "time_ms": 137.35704955004167,
              "speedup": 1.0226600786798967
            }
          ],
          "best_speedup": 1.0226600786798967,
          "status": "success",
          "error": null
        }
      ],
      "summary": {
        "total_benchmarks": 19,
        "successful": 18,
        "failed": 1,
        "skipped_hardware": 0,
        "total_speedups": 12,
        "average_speedup": 5.531627861539351,
        "max_speedup": 45.61156358631169,
        "min_speedup": 1.0226600786798967
      }
    }
  ]
}